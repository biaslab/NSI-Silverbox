{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silverbox\n",
    "\n",
    "Silverbox refers to one of the nonlinear system identification benchmarks on http://nonlinearbenchmark.org/#Silverbox. \n",
    "It is a simulation of a [Duffing oscillator](https://en.wikipedia.org/wiki/Duffing_equation), ocurring for instance in nonlinear spring pendulums.\n",
    "\n",
    "State-space model description of the system:\n",
    "\n",
    "$$\\begin{align}\n",
    "m \\frac{d^2 x(t)}{dt^2} + c \\frac{d x(t)}{dt} + a x(t) + b x^3(t) =&\\ u(t) + w(t) \\\\\n",
    "y(t) =&\\ x(t) + e(t)\n",
    "\\end{align}$$\n",
    "\n",
    "where\n",
    "$$\\begin{align}\n",
    "m     =&\\ \\text{mass} \\\\\n",
    "c     =&\\ \\text{damping} \\\\\n",
    "a     =&\\ \\text{linear stiffness} \\\\\n",
    "b     =&\\ \\text{nonlinear stiffness} \\\\\n",
    "y(t)    =&\\ \\text{observation (displacement)} \\\\\n",
    "x(t)    =&\\ \\text{state (displacement)} \\\\\n",
    "u(t)    =&\\ \\text{force} \\\\\n",
    "v(t)    =&\\ \\text{measurement noise} \\\\\n",
    "w(t)    =&\\ \\text{process noise}\n",
    "\\end{align}$$\n",
    "\n",
    "The process noise is a Wiener process, where the increment is Gaussian distributed $w(t) \\sim \\mathcal{N}(0, \\tau^{-1}dt)$. The parameter $\\tau$ represents the precision of the process. The measurement noise is also a Wiener process, $v(t) \\sim \\mathcal{N}(0, \\xi^{-1}dt)$.\n",
    "\n",
    "## Solution steps\n",
    "\n",
    "### 1. Discretize\n",
    "\n",
    "I'm using a central difference for the second derivative and a forward difference for the first derivative. Let $w_t$ be a sample from $\\mathcal{N}(0, \\tau^{-1})$. The state transition can now be written as the following discrete-time system:\n",
    "\n",
    "$$\\begin{align}\n",
    "m (x_{t+1} - 2x_{t} + x_{t-1}) + c (x_{t+1} - x_{t}) + a x_t + b x_t^3 =&\\ u_t + w_t\n",
    "\\end{align}$$\n",
    "Re-writing this as a function of $x_{t+1}$ yields:\n",
    "$$\\begin{align}\n",
    "% (m + c) x_{t+1}&\\ + (-2m - c + a) x_{t} + bx_t^3 + m x_{t-1} = u_t + w_t \\\\\n",
    "x_{t+1}&\\ = \\frac{2m + c - a}{m + c} x_{t} + \\frac{-b}{m + c}x_t^3 + \\frac{-m}{m + c} x_{t-1} + \\frac{1}{m + c} u_t + \\frac{1}{m + c} w_t \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "### 2. Substitute variables and reduce order\n",
    "\n",
    "I can cast the above system into matrix form:\n",
    "\n",
    "$$ \\underbrace{\\begin{bmatrix} x_{t+1} \\\\ x_{t} \\end{bmatrix}}_{z_t} = \\underbrace{\\begin{bmatrix} 0 & 0 \\\\ 1 & 0 \\end{bmatrix}}_{S} \\underbrace{\\begin{bmatrix} x_{t} \\\\ x_{t-1} \\end{bmatrix}}_{z_{t-1}} + \\underbrace{\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}}_{e} g(z_{t-1}, \\theta) + \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\eta u_t + \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\tilde{w}_t \\, ,$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\begin{align}\n",
    "\\theta_1 =&\\ \\frac{2m+c-a}{m+c} \\\\\n",
    "\\theta_2 =&\\ \\frac{-b}{m+c} \\\\\n",
    "\\theta_3 =&\\ \\frac{-m}{m+c} \\\\\n",
    "\\eta =&\\ \\frac{1}{m+c} \\\\\n",
    "\\gamma^{-1} =& \\tau^{-1} \\frac{1}{(m+c)^2} \\, ,\n",
    "\\end{align}$$\n",
    "\n",
    "and $g(z_{t-1}, \\theta) = \\theta_1 x_t + \\theta_2 x_t^3 + \\theta_3 x_{t-1}$ and $\\tilde{w}_t \\sim \\mathcal{N}(0, \\gamma^{-1})$. In total, I have five unknowns $m,c,a,b,\\tau$ and five equations. I can invert the mapping between $\\phi = (m, c, a, b, \\tau)$ and $\\psi = (\\theta_1, \\theta_2, \\theta_3, \\eta, \\gamma)$ to recover MAP estimates for the physical parameters. Variable substitution allows for more freedom in choosing priors.\n",
    "\n",
    "The system is now a nonlinear autoregressive process:\n",
    "\n",
    "$$z_t = f(z_{t-1}, \\theta, \\eta, u_t) + \\tilde{w}_t$$\n",
    "\n",
    "where $f(z_{t-1}, \\theta, \\eta, u_t) = Sz_{t-1} + e g(z_{t-1}, \\theta) + e \\eta u_t$. Note that we need a two-dimensional state prior now (reminiscent of adding an initial condition on the velocity).\n",
    "\n",
    "### 3. Convert to Gaussian probability\n",
    "\n",
    "Integrating out $\\tilde{w}_t$ and $v_t$ produces a Gaussian state transition node:\n",
    "\n",
    "$$\\begin{align}\n",
    "z_t \\sim&\\ \\mathcal{N}(f(z_{t-1}, \\theta, \\eta, u_t), V) \\\\\n",
    "y_t \\sim&\\ \\mathcal{N}(e^{\\top} z_t, \\xi^{-1}) \\, ,\n",
    "\\end{align}$$\n",
    "\n",
    "where $V = \\begin{bmatrix} \\gamma^{-1} & 0 \\\\ 0 & \\epsilon \\end{bmatrix}$ and $W = V^{-1} = \\begin{bmatrix} \\gamma & 0 \\\\ 0 & \\epsilon^{-1} \\end{bmatrix}$.\n",
    "\n",
    "### 6. Choose priors\n",
    "\n",
    "We know that mass $m$ and process precision $\\gamma$ are strictly positive parameters and that the damping and stiffness coefficients can be both positive and negative. By examing the nonlinear transform $\\psi = G(\\phi)$, we realize that $\\theta_1$, $\\theta_2$, $\\theta_3$ and $\\eta$ can be both positive and negative, but $\\gamma$ can only be positive. As such, we choose the following priors:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\theta \\sim&\\ \\text{Normal}(m^{0}_{\\theta}, V^{0}_{\\theta}) \\\\\n",
    "\\eta \\sim&\\ \\text{Normal}(m^{0}_{\\eta}, v^{0}_{\\eta}) \\\\ \n",
    "\\gamma \\sim&\\ \\text{Gamma}(a^{0}_\\gamma, b^{0}_\\gamma) \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "### 7. Recover physical variables from substituted ones\n",
    "\n",
    "Since we have five equations and five unknowns, we can perfectly recover point estimates of the physical variables from substituted ones. However, we don't want point estimates, we want posteriors. \n",
    "\n",
    "If we approximate $\\gamma$ with a log-Normal distribution and then map it to a Gaussian distribution (i.e. model $\\tilde{\\gamma} = \\log(\\gamma)$), we end up with a Gaussian distributed random vector $\\psi = [\\theta_1, \\theta_2, \\theta_3, \\eta, \\tilde{\\gamma}]$. We can perform a Gaussian approximation of the inverse mapping $G^{-1}(\\psi)$ using a first-order Taylor expansion:\n",
    "\n",
    "$$\\begin{align}\n",
    "m_{\\phi} \\triangleq \\mathbb{E}[G^{-1}(\\psi)] =&\\ G^{-1}(m_{\\psi}) \\\\\n",
    "V_{\\phi} \\triangleq \\mathbb{V}[G^{-1}(\\psi)] =&\\ J_{\\psi}(m_{\\psi}) G^{-1}(m_{\\psi}) J_{\\psi}(m_{\\psi})^{\\top} \\, ,\n",
    "\\end{align}$$\n",
    "\n",
    "The inverse mapping has the form:\n",
    "\n",
    "$$\\begin{align} \n",
    "m =&\\ \\frac{-\\theta_3}{\\eta} \\\\\n",
    "c =&\\ \\frac{1+\\theta_3}{\\eta} \\\\\n",
    "a =&\\ \\frac{(1-\\theta_1 - \\theta_3)}{\\eta} \\\\\n",
    "b =&\\ \\frac{-\\theta_2}{\\eta} \\\\\n",
    "\\tau =&\\ \\tilde{\\gamma} \\eta^2 \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "The Jacobian can be obtained automatically using Julia packages such as ForwardDiff.jl or Zygote.jl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Let's first have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using CSV\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "viz = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV file\n",
    "df = CSV.read(\"../data/SNLS80mV.csv\", ignoreemptylines=true)\n",
    "df = select(df, [:V1, :V2])\n",
    "\n",
    "# Shorthand\n",
    "input = df[:,1]\n",
    "output = df[:,2]\n",
    "\n",
    "# Time horizon\n",
    "T = size(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select training set\n",
    "trn = collect(40101:131072)\n",
    "input_trn = input[trn]\n",
    "output_trn = output[trn]\n",
    "T_trn = length(trn);\n",
    "\n",
    "# Select validation set\n",
    "val = 101:40100\n",
    "input_val = input[val]\n",
    "output_val = output[val]\n",
    "T_val = length(val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot every n-th time-point to avoid figure size exploding\n",
    "n = 100\n",
    "\n",
    "if viz\n",
    "    p1a = Plots.plot(1:n:T_trn, input_trn[1:n:end], color=\"black\", label=\"\", markersize=2, xlabel=\"\", ylabel=\"control\", size=(1200,400), title=\"training\")    \n",
    "    p1b = Plots.plot(1:n:T_trn, output_trn[1:n:end], color=\"black\", label=\"\", markersize=2, xlabel=\"time (t)\", ylabel=\"output (displacement)\", size=(1200,400))    \n",
    "    p1 = plot(p1a, p1b, layout=(2,1))\n",
    "    Plots.savefig(p1, \"viz/training_set.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if viz\n",
    "    p2a = Plots.plot(1:n:T_val, input_val[1:n:end], color=\"black\", label=\"\", markersize=2, xlabel=\"\", ylabel=\"control\", size=(1200,400), title=\"validation\")    \n",
    "    p2b = Plots.plot(1:n:T_val, output_val[1:n:end], color=\"black\", label=\"\", markersize=2, xlabel=\"time (t)\", ylabel=\"output (displacement)\", size=(1200,400))    \n",
    "    p2 = plot(p2a, p2b, layout=(2,1))\n",
    "    Plots.savefig(p2, \"viz/validation_set.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating parameters via Bayesian filtering\n",
    "\n",
    "Implementation with ForneyLab and ARC node. The ARC node is locally modified from the package LAR (https://github.com/biaslab/LAR/). It contains a AutoregressiveControl and AutoregressiveControlNL node, where a nonlinearity g can be provided as an argument.\n",
    "\n",
    "The major change from a linear ARC to a nonlinear ARC node is in working out the expectations for $g(x,\\theta)$ as opposed to $\\theta^{\\top}x$. There are a number of ways of doing this. I have chosen a first-order Taylor approximation:\n",
    "\n",
    "$$ g(x,\\theta) = g(m_x, m_{\\theta}) + J_{x}(m_x, m_{\\theta})^{\\top}(x - m_x) + J_{\\theta}(m_x, m_{\\theta})^{\\top}(\\theta - m_{\\theta}) \\, ,$$\n",
    "\n",
    "where $J_x$ denotes the partial derivative of $g$ with respect to $x$ and $J_{\\theta}$ w.r.t. $\\theta$. Note that our current $g$ is linear in $\\theta$ and you could argue that you don't need to approximate it. However, the first-order Taylor is exact in that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using ForneyLab\n",
    "using ForneyLab: unsafeMean, unsafeCov, unsafeVar, unsafePrecision\n",
    "using ProgressMeter\n",
    "\n",
    "include(\"../ARC-node/ARC.jl\")\n",
    "using .ARC.Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote\n",
    "\n",
    "function Jacobian(F, x)\n",
    "    y = F(x)\n",
    "    n = length(y)\n",
    "    m = length(x)\n",
    "    T = eltype(y)\n",
    "    J = Array{T, 2}(undef, n, m)\n",
    "    for i in 1:n\n",
    "        J[i, :] .= gradient(x -> F(x)[i], x)[1]\n",
    "    end\n",
    "    return J\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start graph\n",
    "graph1 = FactorGraph()\n",
    "\n",
    "# Static parameters\n",
    "@RV θ ~ GaussianMeanPrecision(placeholder(:m_θ, dims=(3,)), placeholder(:w_θ, dims=(3,3)))\n",
    "@RV η ~ GaussianMeanPrecision(placeholder(:m_η), placeholder(:w_η))\n",
    "@RV γ ~ Gamma(placeholder(:a_γ), placeholder(:b_γ))\n",
    "@RV ξ ~ Gamma(placeholder(:a_ξ), placeholder(:b_ξ))\n",
    "\n",
    "# Nonlinearity\n",
    "g(x,θ) = θ[1]*x[1] + θ[2]*x[1]^3 + θ[3]*x[2]\n",
    "\n",
    "# State prior\n",
    "@RV z_tmin1 ~ GaussianMeanPrecision(placeholder(:m_z, dims=(2,)), placeholder(:w_z, dims=(2, 2)), id=:z_tmin1)\n",
    "\n",
    "# Autoregressive node\n",
    "@RV z_t ~ AutoregressiveControlNL(θ, z_tmin1, η, placeholder(:u_t), γ, g=g, id=:z_t)\n",
    "\n",
    "# Specify likelihood\n",
    "@RV y_t ~ GaussianMeanPrecision(dot([1. , 0.], z_t), ξ, id=:y_t)\n",
    "\n",
    "# Placeholder for observation\n",
    "placeholder(y_t, :y_t)\n",
    "\n",
    "# Draw time-slice subgraph\n",
    "ForneyLab.draw(graph1)\n",
    "\n",
    "# Inference algorithm\n",
    "q1 = PosteriorFactorization(z_t, z_tmin1, θ, η, γ, ξ, ids=[:z_t, :z_tmin1, :θ, :η, :γ, :ξ])\n",
    "algo1 = variationalAlgorithm(q1, free_energy=false)\n",
    "source_code1 = algorithmSourceCode(algo1, free_energy=false)\n",
    "eval(Meta.parse(source_code1));\n",
    "# println(source_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference parameters\n",
    "num_iterations = 10\n",
    "\n",
    "# Initialize marginal distribution and observed data dictionaries\n",
    "data = Dict()\n",
    "marginals = Dict()\n",
    "\n",
    "# Initialize arrays of parameterizations\n",
    "params_z = (zeros(2,T_trn+1), repeat(.1 .*float(eye(2)), outer=(1,1,T_trn+1)))\n",
    "params_θ = (ones(3,T_trn+1), repeat(.1 .*float(eye(3)), outer=(1,1,T_trn+1)))\n",
    "params_η = (ones(1,T_trn+1), .1*ones(1,T_trn+1))\n",
    "params_γ = (1e3*ones(1,T_trn+1), 1e1*ones(1,T_trn+1))\n",
    "params_ξ = (1e8*ones(1,T_trn+1), 1e3*ones(1,T_trn+1))\n",
    "\n",
    "# Initialize physical coefficient estimate arrays\n",
    "params_ϕ = (zeros(5,T_trn), zeros(5,5,T_trn))\n",
    "params_ψ = (zeros(5,T_trn), zeros(5,5,T_trn))\n",
    "\n",
    "# Transformations between physical and substituted variables: ψ = G(ϕ) => ϕ = G_inv(ψ)\n",
    "G(ϕ) = [(2*ϕ[1] + ϕ[2] - ϕ[3])/(ϕ[1]+ϕ[2]), -ϕ[4]/(ϕ[1]+ϕ[2]), -ϕ[1]/(ϕ[1]+ϕ[2]), 1/(ϕ[1]+ϕ[2]), ϕ[5]*(ϕ[1]+ϕ[2])^2]\n",
    "G_inv(ψ) = [-ψ[3]/ψ[4], (1+ψ[3])/ψ[4], (1 - ψ[1] - ψ[3])/ψ[4], -ψ[2]/ψ[4], ψ[5]*ψ[4]^2]\n",
    "\n",
    "# Start progress bar\n",
    "p = Progress(T_trn, 1, \"At time \")\n",
    "\n",
    "# Perform inference at each time-step\n",
    "for t = 1:T_trn\n",
    "\n",
    "    # Update progress bar\n",
    "    update!(p, t)\n",
    "    \n",
    "    \"Filtering\"\n",
    "\n",
    "    # Initialize marginals\n",
    "    marginals[:z_tmin1] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_z[1][:,t], w=params_z[2][:,:,t])\n",
    "    marginals[:z_t] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_z[1][:,t], w=params_z[2][:,:,t])\n",
    "    marginals[:θ] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_θ[1][:,t], w=params_θ[2][:,:,t])\n",
    "    marginals[:η] = ProbabilityDistribution(Univariate, GaussianMeanPrecision, m=params_η[1][1,t], w=params_η[2][1,t])\n",
    "    marginals[:γ] = ProbabilityDistribution(Univariate, Gamma, a=params_γ[1][1,t], b=params_γ[2][1,t])\n",
    "    marginals[:ξ] = ProbabilityDistribution(Univariate, Gamma, a=params_ξ[1][1,t], b=params_ξ[2][1,t])\n",
    "    \n",
    "    data = Dict(:y_t => output_trn[t],\n",
    "                :u_t => input_trn[t],\n",
    "                :m_z => params_z[1][:,t],\n",
    "                :w_z => params_z[2][:,:,t],\n",
    "                :m_θ => params_θ[1][:,t],\n",
    "                :w_θ => params_θ[2][:,:,t],\n",
    "                :m_η => params_η[1][1,t],\n",
    "                :w_η => params_η[2][1,t],\n",
    "                :a_γ => params_γ[1][1,t],\n",
    "                :b_γ => params_γ[2][1,t],\n",
    "                :a_ξ => params_ξ[1][1,t],\n",
    "                :b_ξ => params_ξ[2][1,t])\n",
    "\n",
    "    # Iterate variational parameter updates\n",
    "    for i = 1:num_iterations\n",
    "\n",
    "        stepz_tmin1!(data, marginals)\n",
    "        stepz_t!(data, marginals)\n",
    "        stepθ!(data, marginals)\n",
    "        stepη!(data, marginals)\n",
    "        stepγ!(data, marginals)\n",
    "        stepξ!(data, marginals)\n",
    "        \n",
    "    end\n",
    "\n",
    "    # Store current parameterizations of marginals\n",
    "    params_z[1][:,t+1] = unsafeMean(marginals[:z_t])\n",
    "    params_z[2][:,:,t+1] = marginals[:z_t].params[:w]\n",
    "    params_θ[1][:,t+1] = unsafeMean(marginals[:θ])\n",
    "    params_θ[2][:,:,t+1] = marginals[:θ].params[:w]\n",
    "    params_η[1][1,t+1] = unsafeMean(marginals[:η])\n",
    "    params_η[2][1,t+1] = marginals[:η].params[:w]\n",
    "    params_γ[1][1,t+1] = marginals[:γ].params[:a]\n",
    "    params_γ[2][1,t+1] = marginals[:γ].params[:b]\n",
    "    params_ξ[1][1,t+1] = marginals[:ξ].params[:a]\n",
    "    params_ξ[2][1,t+1] = marginals[:ξ].params[:b]\n",
    "    \n",
    "    \"Map substituted to physical variables via first-order Taylor\"\n",
    "    \n",
    "    # Approximate gamma with log-normal via moment-matching\n",
    "    Eγ = unsafeMean(marginals[:γ])\n",
    "    Vγ = unsafeVar(marginals[:γ])\n",
    "    m_γ = log(Eγ^2/sqrt(Vγ + Eγ^2))\n",
    "    v_γ = log(Vγ/Eγ^2 + 1)\n",
    "\n",
    "    # Construct vector of parameter estimates ψ\n",
    "    m_ψ = [unsafeMean(marginals[:θ])[1], unsafeMean(marginals[:θ])[2], unsafeMean(marginals[:θ])[3], unsafeMean(marginals[:η])[1], m_γ]\n",
    "    V_ψ = [unsafeCov(marginals[:θ]) zeros(3,2); zeros(2,3) [unsafeCov(marginals[:η])[1,1] 0;0 v_γ]]\n",
    "    \n",
    "    # Store psi\n",
    "    params_ψ[1][:,t] = m_ψ\n",
    "    params_ψ[2][:,:,t] = V_ψ\n",
    "    \n",
    "    # Compute Jacobian of transformation \n",
    "    J_ψ = Jacobian(G_inv, m_ψ)\n",
    "    \n",
    "    # Compute moments of transformed Gaussian using first-order Taylor approx\n",
    "    m_ϕ = G_inv(m_ψ)\n",
    "    V_ϕ = J_ψ*V_ψ*J_ψ'\n",
    "    \n",
    "    # Store phi\n",
    "    params_ϕ[1][:,t] = m_ϕ\n",
    "    params_ϕ[2][:,:,t] = V_ϕ\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start graph\n",
    "graph2 = FactorGraph()\n",
    "\n",
    "# Nonlinearity\n",
    "g(x,θ) = θ[1]*x[1] + θ[2]*x[1]^3 + θ[3]*x[2]\n",
    "\n",
    "# State prior\n",
    "@RV z_tmin1 ~ GaussianMeanPrecision(placeholder(:m_z, dims=(2,)), placeholder(:w_z, dims=(2, 2)), id=:z_tmin1)\n",
    "\n",
    "# Autoregressive node\n",
    "@RV z_t ~ AutoregressiveControlNL(placeholder(:θ, dims=(3,)), z_tmin1, placeholder(:η), placeholder(:u_t), placeholder(:γ), g=g, id=:z_t)\n",
    "\n",
    "# Draw time-slice subgraph\n",
    "ForneyLab.draw(graph2)\n",
    "\n",
    "# Inference algorithm\n",
    "q2 = PosteriorFactorization(z_t, z_tmin1, ids=[:z_t_val, :z_tmin1_val])\n",
    "algo2 = variationalAlgorithm(q2, free_energy=false)\n",
    "source_code2 = algorithmSourceCode(algo2, free_energy=false)\n",
    "eval(Meta.parse(source_code2));\n",
    "# println(source_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays of parameterizations\n",
    "params_zv = (zeros(2,T_val), repeat(.1 .*Matrix{Float64}(I,2,2), outer=(1,1,T_val)))\n",
    "\n",
    "# State 1\n",
    "params_zv[1][1,1] = output_val[1]\n",
    "params_zv[1][2,1] = output_val[1]\n",
    "params_zv[2][:,:,1] = 1e8*Matrix{Float64}(I,2,2)\n",
    "params_zv[2][:,:,1] = 1e8*Matrix{Float64}(I,2,2)\n",
    "\n",
    "# State 2\n",
    "params_zv[1][1,2] = output_val[2]\n",
    "params_zv[1][2,2] = output_val[1]\n",
    "params_zv[2][:,:,2] = 1e8*Matrix{Float64}(I,2,2)\n",
    "params_zv[2][:,:,2] = 1e8*Matrix{Float64}(I,2,2)\n",
    "\n",
    "# Start progress bar\n",
    "p = Progress(T_val, 1, \"At time \")\n",
    "\n",
    "# Perform inference at each time-step\n",
    "for t = 3:T_val\n",
    "\n",
    "    # Update progress bar\n",
    "    update!(p, t)\n",
    "    \n",
    "    \"Filtering\"\n",
    "\n",
    "    # Initialize marginals\n",
    "    marginals[:z_tmin1] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_zv[1][:,t-1], w=params_zv[2][:,:,t-1])\n",
    "    marginals[:z_t] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_zv[1][:,t-1], w=params_zv[2][:,:,t-1])\n",
    "    \n",
    "    data = Dict(:u_t => input_val[t],\n",
    "                :m_z => params_zv[1][:,t-1],\n",
    "                :w_z => params_zv[2][:,:,t-1],\n",
    "                :θ => params_θ[1][:,end],\n",
    "                :η => params_η[1][end],\n",
    "                :γ => params_γ[1][end]/params_γ[2][end])\n",
    "\n",
    "    # Iterate variational parameter updates\n",
    "    for i = 1:num_iterations\n",
    "        stepz_tmin1_val!(data, marginals)\n",
    "        stepz_t_val!(data, marginals)\n",
    "    end\n",
    "\n",
    "    # Store current parameterizations of marginals\n",
    "    params_zv[1][:,t] = unsafeMean(marginals[:z_t])\n",
    "    params_zv[2][:,:,t] = marginals[:z_t].params[:w]\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize forecasted states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of state marginals\n",
    "estimated_states = params_zv[1][1,:]\n",
    "\n",
    "# Plot every n-th time-point to avoid figure size exploding\n",
    "n = 10\n",
    "\n",
    "p3 = Plots.scatter(1:n:T_val, output_val[1:n:T_val], color=\"black\", label=\"output\", markersize=2, size=(700,400), xlabel=\"time (t)\", ylabel=\"response\", legend=:topleft)\n",
    "Plots.plot!(1:n:T_val, estimated_states[1:n:T_val], color=\"red\", linewidth=1, label=\"estimated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(p3, \"viz/forecasted_states.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error plot\n",
    "pred_error = (estimated_states .- output_val)\n",
    "p4 = Plots.scatter(1:n:T_val, pred_error[1:n:end], color=\"black\", label=\"\", markersize=2, size=(700,400), xlabel=\"time (t)\", ylim=[-0.2, 0.2], ylabel=\"prediction error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(p4, \"viz/forecasted_error.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"RMSE = \"*string(sqrt(mean(pred_error))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize parameter estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of coefficient marginals\n",
    "estimated_θ1_mean = params_θ[1][1,2:end]\n",
    "estimated_θ2_mean = params_θ[1][2,2:end]\n",
    "estimated_θ3_mean = params_θ[1][3,2:end]\n",
    "estimated_θ1_std = sqrt.(inv.(params_θ[2][1,1,2:end]))\n",
    "estimated_θ2_std = sqrt.(inv.(params_θ[2][2,2,2:end]))\n",
    "estimated_θ3_std = sqrt.(inv.(params_θ[2][3,3,2:end]))\n",
    "\n",
    "# Plot both coefficients next to each other\n",
    "p2a = Plots.plot(1:n:T_trn, estimated_θ1_mean[1:n:T_trn], ribbon=[estimated_θ1_std[1:n:T_trn], estimated_θ1_std[1:n:T_trn]], color=\"red\", label=\"θ_1\", xlabel=\"time (t)\", ylim=[1.45, 1.55], legend=:bottomright)\n",
    "p2b = Plots.plot(1:n:T_trn, estimated_θ2_mean[1:n:T_trn], ribbon=[estimated_θ2_std[1:n:T_trn], estimated_θ2_std[1:n:T_trn]], color=\"blue\", label=\"θ_2\", xlabel=\"time (t)\", legend=:topright)\n",
    "p2c = Plots.plot(1:n:T_trn, estimated_θ3_mean[1:n:T_trn], ribbon=[estimated_θ3_std[1:n:T_trn], estimated_θ3_std[1:n:T_trn]], color=\"green\", label=\"θ_3\", xlabel=\"time (t)\", ylim=[-1., -0.9], legend=:topright)\n",
    "p2 = plot(p2a, p2b, p2c, layout=(3,1), size=(800,1200))\n",
    "Plots.savefig(p2, \"viz/forecasted_estimatedθ.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2a = Plots.plot(1:n:T_trn, estimated_θ1_mean[1:n:T_trn], ribbon=[estimated_θ1_std[1:n:T_trn], estimated_θ1_std[1:n:T_trn]], color=\"red\", label=\"θ_1\", xlabel=\"time (t)\", ylim=[1.45, 1.55], legend=:bottomright, size=(600,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(p2a, \"viz/forecasted_estimatedθ1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2b = Plots.plot(1:n:T_trn, estimated_θ2_mean[1:n:T_trn], ribbon=[estimated_θ2_std[1:n:T_trn], estimated_θ2_std[1:n:T_trn]], color=\"blue\", label=\"θ_2\", xlabel=\"time (t)\", legend=:topright, size=(600,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(p2b, \"viz/forecasted_estimatedθ2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2c = Plots.plot(1:n:T_trn, estimated_θ3_mean[1:n:T_trn], ribbon=[estimated_θ3_std[1:n:T_trn], estimated_θ3_std[1:n:T_trn]], color=\"green\", label=\"θ_3\", xlabel=\"time (t)\", ylim=[-1., -0.9], legend=:topright, size=(600,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(p2c, \"viz/forecasted_estimatedθ3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of control coefficient marginals\n",
    "estimated_η_mean = params_η[1][1,2:end]\n",
    "estimated_η_std = sqrt.(inv.(params_η[2][1,2:end]))\n",
    "\n",
    "# Plot both coefficients next to each other\n",
    "p3 = Plots.plot(1:n:T_trn, estimated_η_mean[1:n:T_trn], ribbon=[estimated_η_std[1:n:T_trn], estimated_η_std[1:n:T_trn]], color=\"blue\", label=\"η\", xlabel=\"time (t)\", ylim=[0.15, .32], size=(600,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(p3, \"viz/forecasted_estimatedη.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of process precision marginals\n",
    "estimated_γ_mean = params_γ[1][1,2:end] ./ params_γ[2][1,2:end]\n",
    "estimated_γ_std = sqrt.(params_γ[1][1,2:end] ./ params_γ[2][1,2:end].^2)\n",
    "\n",
    "# Plot both coefficients next to each other\n",
    "p4 = Plots.plot(1:n:T_trn, estimated_γ_mean[1:n:T_trn], ribbon=[estimated_γ_std[1:n:T_trn], estimated_γ_std[1:n:T_trn]], color=\"blue\", label=\"γ\", xlabel=\"time (t)\", size=(600,400), legend=:bottomright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(p4, \"viz/forecasted_estimatedγ.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of measurement precision marginals\n",
    "estimated_ξ_mean = params_ξ[1][1,2:end] ./ params_ξ[2][1,2:end]\n",
    "estimated_ξ_std = sqrt.(params_ξ[1][1,2:end] ./ params_ξ[2][1,2:end].^2)\n",
    "\n",
    "# Plot both coefficients next to each other\n",
    "p8 = Plots.plot(1:n:T_trn, estimated_ξ_mean[1:n:T_trn], ribbon=[estimated_ξ_std[1:n:T_trn], estimated_ξ_std[1:n:T_trn]], color=\"blue\", label=\"measurement-precision\", xlabel=\"time (t)\", size=(600,400), legend=:topleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(p8, \"viz/forecasted_measurement-precision.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
