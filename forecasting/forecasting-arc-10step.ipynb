{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silverbox\n",
    "\n",
    "Silverbox refers to one of the nonlinear system identification benchmarks on http://nonlinearbenchmark.org/#Silverbox. \n",
    "It is a simulation of a [Duffing oscillator](https://en.wikipedia.org/wiki/Duffing_equation), ocurring for instance in nonlinear spring pendulums.\n",
    "\n",
    "State-space model description of the system:\n",
    "\n",
    "$$\\begin{align}\n",
    "m \\frac{d^2 x(t)}{dt^2} + c \\frac{d x(t)}{dt} + a x(t) + b x^3(t) =&\\ u(t) + w(t) \\\\\n",
    "y(t) =&\\ x(t) + e(t)\n",
    "\\end{align}$$\n",
    "\n",
    "where\n",
    "$$\\begin{align}\n",
    "m     =&\\ \\text{mass} \\\\\n",
    "c     =&\\ \\text{damping} \\\\\n",
    "a     =&\\ \\text{linear stiffness} \\\\\n",
    "b     =&\\ \\text{nonlinear stiffness} \\\\\n",
    "y(t)    =&\\ \\text{observation (displacement)} \\\\\n",
    "x(t)    =&\\ \\text{state (displacement)} \\\\\n",
    "u(t)    =&\\ \\text{force} \\\\\n",
    "v(t)    =&\\ \\text{measurement noise} \\\\\n",
    "w(t)    =&\\ \\text{process noise}\n",
    "\\end{align}$$\n",
    "\n",
    "The process noise is a Wiener process, where the increment is Gaussian distributed $w(t) \\sim \\mathcal{N}(0, \\tau^{-1}dt)$. The parameter $\\tau$ represents the precision of the process. The measurement noise is also a Wiener process, $v(t) \\sim \\mathcal{N}(0, \\xi^{-1}dt)$.\n",
    "\n",
    "## Solution steps\n",
    "\n",
    "### 1. Discretize\n",
    "\n",
    "I'm using a central difference for the second derivative and a forward difference for the first derivative. Let $w_t$ be a sample from $\\mathcal{N}(0, \\tau^{-1})$. The state transition can now be written as the following discrete-time system:\n",
    "\n",
    "$$\\begin{align}\n",
    "m (x_{t+1} - 2x_{t} + x_{t-1}) + c (x_{t+1} - x_{t}) + a x_t + b x_t^3 =&\\ u_t + w_t\n",
    "\\end{align}$$\n",
    "Re-writing this as a function of $x_{t+1}$ yields:\n",
    "$$\\begin{align}\n",
    "% (m + c) x_{t+1}&\\ + (-2m - c + a) x_{t} + bx_t^3 + m x_{t-1} = u_t + w_t \\\\\n",
    "x_{t+1}&\\ = \\frac{2m + c - a}{m + c} x_{t} + \\frac{-b}{m + c}x_t^3 + \\frac{-m}{m + c} x_{t-1} + \\frac{1}{m + c} u_t + \\frac{1}{m + c} w_t \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "### 2. Substitute variables and reduce order\n",
    "\n",
    "I can cast the above system into matrix form:\n",
    "\n",
    "$$ \\underbrace{\\begin{bmatrix} x_{t+1} \\\\ x_{t} \\end{bmatrix}}_{z_t} = \\underbrace{\\begin{bmatrix} 0 & 0 \\\\ 1 & 0 \\end{bmatrix}}_{S} \\underbrace{\\begin{bmatrix} x_{t} \\\\ x_{t-1} \\end{bmatrix}}_{z_{t-1}} + \\underbrace{\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}}_{e} g(z_{t-1}, \\theta) + \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\eta u_t + \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\tilde{w}_t \\, ,$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\begin{align}\n",
    "\\theta_1 =&\\ \\frac{2m+c-a}{m+c} \\\\\n",
    "\\theta_2 =&\\ \\frac{-b}{m+c} \\\\\n",
    "\\theta_3 =&\\ \\frac{-m}{m+c} \\\\\n",
    "\\eta =&\\ \\frac{1}{m+c} \\\\\n",
    "\\gamma^{-1} =& \\tau^{-1} \\frac{1}{(m+c)^2} \\, ,\n",
    "\\end{align}$$\n",
    "\n",
    "and $g(z_{t-1}, \\theta) = \\theta_1 x_t + \\theta_2 x_t^3 + \\theta_3 x_{t-1}$ and $\\tilde{w}_t \\sim \\mathcal{N}(0, \\gamma^{-1})$. In total, I have five unknowns $m,c,a,b,\\tau$ and five equations. I can invert the mapping between $\\phi = (m, c, a, b, \\tau)$ and $\\psi = (\\theta_1, \\theta_2, \\theta_3, \\eta, \\gamma)$ to recover MAP estimates for the physical parameters. Variable substitution allows for more freedom in choosing priors.\n",
    "\n",
    "The system is now a nonlinear autoregressive process:\n",
    "\n",
    "$$z_t = f(z_{t-1}, \\theta, \\eta, u_t) + \\tilde{w}_t$$\n",
    "\n",
    "where $f(z_{t-1}, \\theta, \\eta, u_t) = Sz_{t-1} + e g(z_{t-1}, \\theta) + e \\eta u_t$. Note that we need a two-dimensional state prior now (reminiscent of adding an initial condition on the velocity).\n",
    "\n",
    "### 3. Convert to Gaussian probability\n",
    "\n",
    "Integrating out $\\tilde{w}_t$ and $v_t$ produces a Gaussian state transition node:\n",
    "\n",
    "$$\\begin{align}\n",
    "z_t \\sim&\\ \\mathcal{N}(f(z_{t-1}, \\theta, \\eta, u_t), V) \\\\\n",
    "y_t \\sim&\\ \\mathcal{N}(e^{\\top} z_t, \\xi^{-1}) \\, ,\n",
    "\\end{align}$$\n",
    "\n",
    "where $V = \\begin{bmatrix} \\gamma^{-1} & 0 \\\\ 0 & \\epsilon \\end{bmatrix}$ and $W = V^{-1} = \\begin{bmatrix} \\gamma & 0 \\\\ 0 & \\epsilon^{-1} \\end{bmatrix}$.\n",
    "\n",
    "### 6. Choose priors\n",
    "\n",
    "We know that mass $m$ and process precision $\\gamma$ are strictly positive parameters and that the damping and stiffness coefficients can be both positive and negative. By examing the nonlinear transform $\\psi = G(\\phi)$, we realize that $\\theta_1$, $\\theta_2$, $\\theta_3$ and $\\eta$ can be both positive and negative, but $\\gamma$ can only be positive. As such, we choose the following priors:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\theta \\sim&\\ \\text{Normal}(m^{0}_{\\theta}, V^{0}_{\\theta}) \\\\\n",
    "\\eta \\sim&\\ \\text{Normal}(m^{0}_{\\eta}, v^{0}_{\\eta}) \\\\ \n",
    "\\gamma \\sim&\\ \\text{Gamma}(a^{0}_\\gamma, b^{0}_\\gamma) \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "### 7. Recover physical variables from substituted ones\n",
    "\n",
    "Since we have five equations and five unknowns, we can perfectly recover point estimates of the physical variables from substituted ones. However, we don't want point estimates, we want posteriors. \n",
    "\n",
    "If we approximate $\\gamma$ with a log-Normal distribution and then map it to a Gaussian distribution (i.e. model $\\tilde{\\gamma} = \\log(\\gamma)$), we end up with a Gaussian distributed random vector $\\psi = [\\theta_1, \\theta_2, \\theta_3, \\eta, \\tilde{\\gamma}]$. We can perform a Gaussian approximation of the inverse mapping $G^{-1}(\\psi)$ using a first-order Taylor expansion:\n",
    "\n",
    "$$\\begin{align}\n",
    "m_{\\phi} \\triangleq \\mathbb{E}[G^{-1}(\\psi)] =&\\ G^{-1}(m_{\\psi}) \\\\\n",
    "V_{\\phi} \\triangleq \\mathbb{V}[G^{-1}(\\psi)] =&\\ J_{\\psi}(m_{\\psi}) G^{-1}(m_{\\psi}) J_{\\psi}(m_{\\psi})^{\\top} \\, ,\n",
    "\\end{align}$$\n",
    "\n",
    "The inverse mapping has the form:\n",
    "\n",
    "$$\\begin{align} \n",
    "m =&\\ \\frac{-\\theta_3}{\\eta} \\\\\n",
    "c =&\\ \\frac{1+\\theta_3}{\\eta} \\\\\n",
    "a =&\\ \\frac{(1-\\theta_1 - \\theta_3)}{\\eta} \\\\\n",
    "b =&\\ \\frac{-\\theta_2}{\\eta} \\\\\n",
    "\\tau =&\\ \\tilde{\\gamma} \\eta^2 \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "The Jacobian can be obtained automatically using Julia packages such as ForwardDiff.jl or Zygote.jl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Let's first have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using CSV\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "pyplot()\n",
    "viz = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV file\n",
    "df = CSV.read(\"../data/SNLS80mV.csv\", ignoreemptylines=true)\n",
    "df = select(df, [:V1, :V2])\n",
    "\n",
    "# Shorthand\n",
    "input = df[:,1]\n",
    "output = df[:,2]\n",
    "\n",
    "# Time horizon\n",
    "T = size(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip data to constant amplitude regime\n",
    "clip_ix = collect(40101:127500)\n",
    "# clip_ix = 40575:49250\n",
    "# clip_ix = 1:131072\n",
    "input_ = input[clip_ix]\n",
    "output_ = output[clip_ix]\n",
    "T_ = length(clip_ix);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot every n-th time-point to avoid figure size exploding\n",
    "n = 40\n",
    "\n",
    "if viz\n",
    "    p1a = Plots.plot(1:n:T_, input_[1:n:end], color=\"black\", label=\"\", markersize=2, xlabel=\"\", ylabel=\"control\", size=(1200,400), title=\"training\")    \n",
    "    p1b = Plots.plot(1:n:T_, output_[1:n:end], color=\"black\", label=\"\", markersize=2, xlabel=\"time (t)\", ylabel=\"output (displacement)\", size=(1200,400))    \n",
    "    p1 = plot(p1a, p1b, layout=(2,1))\n",
    "#     Plots.savefig(p1, \"viz/constant-amp-regime.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 4\n",
    "ix = 126000:ss:127500\n",
    "p31 = Plots.plot(ix, output[ix], color=\"green\", markersize=2, xlabel=\"time (t)\", label=\"output (displacement)\", linestyle=:dashdot)    \n",
    "Plots.plot!(ix, input[ix], color=\"purple\", markersize=2, xlabel=\"time (t)\", label=\"input (control)\", size=(1400,300), ylim=[-.16, .21], legend=:topright, tickfontsize=14, legendfontsize=14, ylabel=\"signal\", guidefontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(p31, \"viz/input-output_seq1.png\")\n",
    "Plots.savefig(p31, \"viz/input-output_seq1.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating parameters via Bayesian filtering\n",
    "\n",
    "Implementation with ForneyLab and a custom AR node. The ARC node is locally modified from the package LAR (https://github.com/biaslab/LAR/). ARC contains a AutoregressiveControlNL node, where the control signal is absorbed into the standard AR node and a nonlinearity $g$ can be supplied as keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using ForneyLab\n",
    "using ForneyLab: unsafeMean, unsafeCov, unsafeVar, unsafePrecision\n",
    "using ProgressMeter\n",
    "\n",
    "include(\"../ARC-node/ARC.jl\")\n",
    "using .ARC.Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote\n",
    "\n",
    "function Jacobian(F, x)\n",
    "    y = F(x)\n",
    "    n = length(y)\n",
    "    m = length(x)\n",
    "    T = eltype(y)\n",
    "    J = Array{T, 2}(undef, n, m)\n",
    "    for i in 1:n\n",
    "        J[i, :] .= gradient(x -> F(x)[i], x)[1]\n",
    "    end\n",
    "    return J\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System identification graph\n",
    "graph1 = FactorGraph()\n",
    "\n",
    "# Static parameters\n",
    "@RV θ ~ GaussianMeanPrecision(placeholder(:m_θ, dims=(3,)), placeholder(:w_θ, dims=(3,3)))\n",
    "@RV η ~ GaussianMeanPrecision(placeholder(:m_η), placeholder(:w_η))\n",
    "@RV γ ~ Gamma(placeholder(:a_γ), placeholder(:b_γ))\n",
    "@RV ξ ~ Gamma(placeholder(:a_ξ), placeholder(:b_ξ))\n",
    "\n",
    "# Nonlinearity\n",
    "g(x,θ) = θ[1]*x[1] + θ[2]*x[1]^3 + θ[3]*x[2]\n",
    "\n",
    "# State prior\n",
    "@RV z_tmin1 ~ GaussianMeanPrecision(placeholder(:m_z, dims=(2,)), placeholder(:w_z, dims=(2, 2)), id=:z_tmin1)\n",
    "\n",
    "# Autoregressive node\n",
    "@RV z_t ~ AutoregressiveControlNL(θ, z_tmin1, η, placeholder(:u_t), γ, g=g, id=:z_t)\n",
    "\n",
    "# Specify likelihood\n",
    "@RV y_t ~ GaussianMeanPrecision(dot([1. , 0.], z_t), ξ, id=:y_t)\n",
    "\n",
    "# Placeholder for observation\n",
    "placeholder(y_t, :y_t)\n",
    "\n",
    "# Draw time-slice subgraph\n",
    "ForneyLab.draw(graph1)\n",
    "\n",
    "# Inference algorithm\n",
    "q1 = PosteriorFactorization(z_t, z_tmin1, θ, η, γ, ξ, ids=[:z_t, :z_tmin1, :θ, :η, :γ, :ξ])\n",
    "algo1 = variationalAlgorithm(q1, free_energy=false)\n",
    "source_code1 = algorithmSourceCode(algo1, free_energy=false)\n",
    "eval(Meta.parse(source_code1));\n",
    "# println(source_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting graph\n",
    "graph2 = FactorGraph()\n",
    "\n",
    "# State prior\n",
    "@RV z_pred_tmin1 ~ GaussianMeanPrecision(placeholder(:m_z_, dims=(2,)), placeholder(:w_z, dims=(2, 2)), id=:z_pred_tmin1)\n",
    "\n",
    "# Autoregressive node\n",
    "@RV z_pred_t ~ AutoregressiveControlNL(placeholder(:θ, dims=(3,)), z_pred, placeholder(:η), placeholder(:u_t), placeholder(:γ), g=g, id=:z_pred_t)\n",
    "\n",
    "# Draw time-slice subgraph\n",
    "ForneyLab.draw(graph2)\n",
    "\n",
    "# Inference algorithm\n",
    "q2 = PosteriorFactorization(z_pred_t, z_pred_tmin1, ids=[:z_pred_t, :z_pred_tmin1])\n",
    "algo2 = variationalAlgorithm(q2, free_energy=false)\n",
    "source_code2 = algorithmSourceCode(algo2, free_energy=false)\n",
    "eval(Meta.parse(source_code2));\n",
    "# println(source_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer parameters and forecast several steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of steps ahead\n",
    "TT = 10\n",
    "\n",
    "# Inference parameters\n",
    "num_iterations = 10\n",
    "\n",
    "# Initialize marginal distribution and observed data dictionaries\n",
    "data = Dict()\n",
    "marginals = Dict()\n",
    "\n",
    "# Initialize arrays of parameterizations\n",
    "params_z = (zeros(2,T_ - TT), repeat(.1 .*float(eye(2)), outer=(1,1,T_ - TT)))\n",
    "params_θ = (ones(3,T_ - TT), repeat(.1 .*float(eye(3)), outer=(1,1,T_ - TT)))\n",
    "params_η = (ones(1,T_ - TT), .1*ones(1,T_ - TT))\n",
    "params_γ = (1e3*ones(1,T_ - TT), 1e1*ones(1,T_ - TT))\n",
    "params_ξ = (1e8*ones(1,T_ - TT), 1e3*ones(1,T_ - TT))\n",
    "\n",
    "# Initialize coefficient vector arrays\n",
    "params_ϕ = (zeros(5,T_ - TT), zeros(5,5,T_ - TT))\n",
    "params_ψ = (zeros(5,T_ - TT), zeros(5,5,T_ - TT))\n",
    "\n",
    "# Initialize future state arrays\n",
    "params_zpred_nar = (zeros(2, T_ - TT, TT+1), repeat(.1 .*float(eye(2)), outer=(1,1,T_ - TT, TT+1)))\n",
    "pred_diff_nar = zeros(T_ - TT, TT)\n",
    "pred_pwerr_nar = zeros(T_ - TT, TT)\n",
    "\n",
    "# Transformations between physical and substituted variables: ψ = G(ϕ) => ϕ = G_inv(ψ)\n",
    "G(ϕ) = [(2*ϕ[1] + ϕ[2] - ϕ[3])/(ϕ[1]+ϕ[2]), -ϕ[4]/(ϕ[1]+ϕ[2]), -ϕ[1]/(ϕ[1]+ϕ[2]), 1/(ϕ[1]+ϕ[2]), ϕ[5]*(ϕ[1]+ϕ[2])^2]\n",
    "G_inv(ψ) = [-ψ[3]/ψ[4], (1+ψ[3])/ψ[4], (1 - ψ[1] - ψ[3])/ψ[4], -ψ[2]/ψ[4], ψ[5]*ψ[4]^2]\n",
    "\n",
    "# Start progress bar\n",
    "p = Progress(T_ - TT, 1, \"At time \")\n",
    "\n",
    "# Perform inference at each time-step\n",
    "for t = 2:(T_ - TT)\n",
    "\n",
    "    # Update progress bar\n",
    "    update!(p, t)\n",
    "    \n",
    "    \"Filtering\"\n",
    "\n",
    "    # Initialize marginals\n",
    "    marginals[:z_tmin1] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_z[1][:,t-1], w=params_z[2][:,:,t-1])\n",
    "    marginals[:z_t] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_z[1][:,t-1], w=params_z[2][:,:,t-1])\n",
    "    marginals[:θ] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_θ[1][:,t-1], w=params_θ[2][:,:,t-1])\n",
    "    marginals[:η] = ProbabilityDistribution(Univariate, GaussianMeanPrecision, m=params_η[1][1,t-1], w=params_η[2][1,t-1])\n",
    "    marginals[:γ] = ProbabilityDistribution(Univariate, Gamma, a=params_γ[1][1,t-1], b=params_γ[2][1,t-1])\n",
    "    marginals[:ξ] = ProbabilityDistribution(Univariate, Gamma, a=params_ξ[1][1,t-1], b=params_ξ[2][1,t-1])\n",
    "    \n",
    "    data = Dict(:y_t => output_[t],\n",
    "                :u_t => input_[t],\n",
    "                :m_z => params_z[1][:,t-1],\n",
    "                :w_z => params_z[2][:,:,t-1],\n",
    "                :m_θ => params_θ[1][:,t-1],\n",
    "                :w_θ => params_θ[2][:,:,t-1],\n",
    "                :m_η => params_η[1][1,t-1],\n",
    "                :w_η => params_η[2][1,t-1],\n",
    "                :a_γ => params_γ[1][1,t-1],\n",
    "                :b_γ => params_γ[2][1,t-1],\n",
    "                :a_ξ => params_ξ[1][1,t-1],\n",
    "                :b_ξ => params_ξ[2][1,t-1])\n",
    "\n",
    "    # Iterate variational parameter updates\n",
    "    for i = 1:num_iterations\n",
    "\n",
    "        stepz_t!(data, marginals)\n",
    "        stepθ!(data, marginals)\n",
    "        stepη!(data, marginals)\n",
    "        stepγ!(data, marginals)\n",
    "        stepξ!(data, marginals)\n",
    "#         stepz_tmin1!(data, marginals)\n",
    "    \n",
    "    end\n",
    "\n",
    "    # Store current parameterizations of marginals\n",
    "    params_z[1][:,t] = unsafeMean(marginals[:z_t])\n",
    "    params_z[2][:,:,t] = marginals[:z_t].params[:w]\n",
    "    params_θ[1][:,t] = unsafeMean(marginals[:θ])\n",
    "    params_θ[2][:,:,t] = marginals[:θ].params[:w]\n",
    "    params_η[1][1,t] = unsafeMean(marginals[:η])\n",
    "    params_η[2][1,t] = marginals[:η].params[:w]\n",
    "    params_γ[1][1,t] = marginals[:γ].params[:a]\n",
    "    params_γ[2][1,t] = marginals[:γ].params[:b]\n",
    "    params_ξ[1][1,t] = marginals[:ξ].params[:a]\n",
    "    params_ξ[2][1,t] = marginals[:ξ].params[:b]\n",
    "    \n",
    "    \"Map substituted to physical variables via first-order Taylor\"\n",
    "    \n",
    "    # Approximate gamma with log-normal via moment-matching\n",
    "    Eγ = unsafeMean(marginals[:γ])\n",
    "    Vγ = unsafeVar(marginals[:γ])\n",
    "    m_γ = log(Eγ^2/sqrt(Vγ + Eγ^2))\n",
    "    v_γ = log(Vγ/Eγ^2 + 1)\n",
    "\n",
    "    # Construct vector of parameter estimates ψ\n",
    "    m_ψ = [unsafeMean(marginals[:θ])[1], unsafeMean(marginals[:θ])[2], unsafeMean(marginals[:θ])[3], unsafeMean(marginals[:η])[1], m_γ]\n",
    "    V_ψ = [unsafeCov(marginals[:θ]) zeros(3,2); zeros(2,3) [unsafeCov(marginals[:η])[1,1] 0;0 v_γ]]\n",
    "    \n",
    "    # Store psi\n",
    "    params_ψ[1][:,t] = m_ψ\n",
    "    params_ψ[2][:,:,t] = V_ψ\n",
    "    \n",
    "    # Compute Jacobian of transformation \n",
    "    J_ψ = Jacobian(G_inv, m_ψ)\n",
    "    \n",
    "    # Compute moments of transformed Gaussian using first-order Taylor approx\n",
    "    m_ϕ = G_inv(m_ψ)\n",
    "    V_ϕ = J_ψ*V_ψ*J_ψ'\n",
    "    \n",
    "    # Store phi\n",
    "    params_ϕ[1][:,t] = m_ϕ\n",
    "    params_ϕ[2][:,:,t] = V_ϕ\n",
    "    \n",
    "    \"Forecast several steps ahead\"\n",
    "    \n",
    "    if T_ > 2\n",
    "    \n",
    "        params_zpred_nar[1][:,t,1] = params_z[1][:,t]\n",
    "        params_zpred_nar[2][:,:,t,1] = params_z[2][:,:,t]\n",
    "\n",
    "        for tt = 1:TT\n",
    "\n",
    "            # Initialize marginals\n",
    "            marginals[:z_pred_tmin1] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_zpred_nar[1][:,t,tt], w=params_zpred_nar[2][:,:,t,tt])\n",
    "            marginals[:z_pred_t] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_zpred_nar[1][:,t,tt], w=params_zpred_nar[2][:,:,t,tt])\n",
    "\n",
    "            data = Dict(:u_t => input_[t+tt],\n",
    "                        :m_z => params_zpred_nar[1][:,t,tt],\n",
    "                        :w_z => params_zpred_nar[2][:,:,t,tt],\n",
    "                        :θ => params_θ[1][:,t],\n",
    "                        :η => params_η[1][t],\n",
    "                        :γ => params_γ[1][t]/params_γ[2][t])\n",
    "\n",
    "            # Iterate variational parameter updates\n",
    "            for i = 1:num_iterations\n",
    "                stepz_pred_t!(data, marginals)\n",
    "                stepz_pred_tmin1!(data, marginals)\n",
    "            end\n",
    "\n",
    "            # Store current parameterizations of marginals\n",
    "            params_zpred_nar[1][:,t,tt+1] = unsafeMean(marginals[:z_pred_t])\n",
    "            params_zpred_nar[2][:,:,t,tt+1] = marginals[:z_pred_t].params[:w]\n",
    "\n",
    "        end\n",
    "\n",
    "        # Evaluate prediction error for forecast\n",
    "        pred_diff_nar[t,:] = (params_zpred_nar[1][1,t,2:end] .- output_[t+1:t+TT])\n",
    "        pred_pwerr_nar[t,:] = params_zpred_nar[2][1,1,t,2:end].*(params_zpred_nar[1][1,t,2:end] .- output_[t+1:t+TT]).^2\n",
    "\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a time-point and visualize forecasting\n",
    "t = 87200\n",
    "\n",
    "# Mean and std dev of predictions\n",
    "zpred_nar_mean = params_zpred_nar[1][1,t,2:TT+1]\n",
    "zpred_nar_std = sqrt.(inv.(params_zpred_nar[2][1,1,t,2:TT+1])) \n",
    "\n",
    "\n",
    "scatter(output_[t+1:t+TT], label=\"observations\", xlabel=\"time-steps ahead\")\n",
    "plot!(zpred_nar_mean, ribbon=[zpred_nar_std, zpred_nar_std], label=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a number of steps ahead\n",
    "tt = 9\n",
    "\n",
    "# Extract mean of state marginals\n",
    "estimated_states_nar = params_zpred_nar[1][1,:,1+tt]\n",
    "\n",
    "# Plot every n-th time-point to avoid figure size exploding\n",
    "n = 100\n",
    "\n",
    "p23 = Plots.scatter(output_[1:n:end], color=\"black\", label=\"output\", markersize=2, size=(800,400), xlabel=\"time (t)\", ylabel=\"response\", legend=:bottomleft)\n",
    "Plots.plot!(estimated_states_nar[1:n:end], color=\"red\", linewidth=1, label=\"estimated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(p23, \"viz/forecasted-states-nar_\"*string(tt)*\"stepahead.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines - linear\n",
    "\n",
    "We can ignore the nonlinear component. This will be a good baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System identification graph\n",
    "graph3 = FactorGraph()\n",
    "\n",
    "# Static parameters\n",
    "@RV θ ~ GaussianMeanPrecision(placeholder(:m_θ, dims=(2,)), placeholder(:w_θ, dims=(2,2)))\n",
    "@RV η ~ GaussianMeanPrecision(placeholder(:m_η), placeholder(:w_η))\n",
    "@RV γ ~ Gamma(placeholder(:a_γ), placeholder(:b_γ))\n",
    "@RV ξ ~ Gamma(placeholder(:a_ξ), placeholder(:b_ξ))\n",
    "\n",
    "# State prior\n",
    "@RV z_tmin1 ~ GaussianMeanPrecision(placeholder(:m_z, dims=(2,)), placeholder(:w_z, dims=(2, 2)), id=:z_tmin1)\n",
    "\n",
    "# Autoregressive node\n",
    "@RV z_t ~ AutoregressiveControl(θ, z_tmin1, η, placeholder(:u_t), γ, id=:z_t)\n",
    "\n",
    "# Specify likelihood\n",
    "@RV y_t ~ GaussianMeanPrecision(dot([1. , 0.], z_t), ξ, id=:y_t)\n",
    "\n",
    "# Placeholder for observation\n",
    "placeholder(y_t, :y_t)\n",
    "\n",
    "# Draw time-slice subgraph\n",
    "ForneyLab.draw(graph1)\n",
    "\n",
    "# Inference algorithm\n",
    "q1 = PosteriorFactorization(z_t, z_tmin1, θ, η, γ, ξ, ids=[:z_t, :z_tmin1, :θ, :η, :γ, :ξ])\n",
    "algo1 = variationalAlgorithm(q1, free_energy=false)\n",
    "source_code1 = algorithmSourceCode(algo1, free_energy=false)\n",
    "eval(Meta.parse(source_code1));\n",
    "# println(source_code)\n",
    "\n",
    "# Forecasting graph\n",
    "graph4= FactorGraph()\n",
    "\n",
    "# State prior\n",
    "@RV z_pred_tmin1 ~ GaussianMeanPrecision(placeholder(:m_z, dims=(2,)), placeholder(:w_z, dims=(2, 2)), id=:z_tmin1)\n",
    "\n",
    "# Autoregressive node\n",
    "@RV z_pred_t ~ AutoregressiveControl(placeholder(:θ, dims=(2,)), z_pred_tmin1, placeholder(:η), placeholder(:u_t), placeholder(:γ), id=:z_t)\n",
    "\n",
    "# Draw time-slice subgraph\n",
    "ForneyLab.draw(graph4)\n",
    "\n",
    "# Inference algorithm\n",
    "q4 = PosteriorFactorization(z_pred_t, z_pred_tmin1, ids=[:z_pred_t, :z_pred_tmin1])\n",
    "algo4 = variationalAlgorithm(q4, free_energy=false)\n",
    "source_code4 = algorithmSourceCode(algo4, free_energy=false)\n",
    "eval(Meta.parse(source_code4));\n",
    "# println(source_code4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of steps ahead\n",
    "TT = 10\n",
    "\n",
    "# Inference parameters\n",
    "num_iterations = 10\n",
    "\n",
    "# Initialize marginal distribution and observed data dictionaries\n",
    "data = Dict()\n",
    "marginals = Dict()\n",
    "\n",
    "# Initialize arrays of parameterizations\n",
    "params_z = (zeros(2,T_ - TT), repeat(.1 .*float(eye(2)), outer=(1,1,T_ - TT)))\n",
    "params_θ = (ones(2,T_ - TT), repeat(.1 .*float(eye(2)), outer=(1,1,T_ - TT)))\n",
    "params_η = (ones(1,T_ - TT), .1*ones(1,T_ - TT))\n",
    "params_γ = (1e3*ones(1,T_ - TT), 1e1*ones(1,T_ - TT))\n",
    "params_ξ = (1e8*ones(1,T_ - TT), 1e3*ones(1,T_ - TT))\n",
    "\n",
    "# Initialize future state arrays\n",
    "params_zpred_lar = (zeros(2, T_ - TT, TT+1), repeat(.1 .*float(eye(2)), outer=(1,1,T_ - TT, TT+1)))\n",
    "pred_diff_lar = zeros(T_ - TT, TT)\n",
    "pred_pwerr_lar = zeros(T_ - TT, TT)\n",
    "\n",
    "# Start progress bar\n",
    "p = Progress(T_ - TT, 1, \"At time \")\n",
    "\n",
    "# Perform inference at each time-step\n",
    "for t = 2:(T_ - TT)\n",
    "\n",
    "    # Update progress bar\n",
    "    update!(p, t)\n",
    "    \n",
    "    \"Filtering\"\n",
    "\n",
    "    # Initialize marginals\n",
    "    marginals[:z_tmin1] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_z[1][:,t-1], w=params_z[2][:,:,t-1])\n",
    "    marginals[:z_t] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_z[1][:,t-1], w=params_z[2][:,:,t-1])\n",
    "    marginals[:θ] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_θ[1][:,t-1], w=params_θ[2][:,:,t-1])\n",
    "    marginals[:η] = ProbabilityDistribution(Univariate, GaussianMeanPrecision, m=params_η[1][1,t-1], w=params_η[2][1,t-1])\n",
    "    marginals[:γ] = ProbabilityDistribution(Univariate, Gamma, a=params_γ[1][1,t-1], b=params_γ[2][1,t-1])\n",
    "    marginals[:ξ] = ProbabilityDistribution(Univariate, Gamma, a=params_ξ[1][1,t-1], b=params_ξ[2][1,t-1])\n",
    "    \n",
    "    data = Dict(:y_t => output_[t],\n",
    "                :u_t => input_[t],\n",
    "                :m_z => params_z[1][:,t-1],\n",
    "                :w_z => params_z[2][:,:,t-1],\n",
    "                :m_θ => params_θ[1][:,t-1],\n",
    "                :w_θ => params_θ[2][:,:,t-1],\n",
    "                :m_η => params_η[1][1,t-1],\n",
    "                :w_η => params_η[2][1,t-1],\n",
    "                :a_γ => params_γ[1][1,t-1],\n",
    "                :b_γ => params_γ[2][1,t-1],\n",
    "                :a_ξ => params_ξ[1][1,t-1],\n",
    "                :b_ξ => params_ξ[2][1,t-1])\n",
    "\n",
    "    # Iterate variational parameter updates\n",
    "    for i = 1:num_iterations\n",
    "\n",
    "        stepz_t!(data, marginals)\n",
    "        stepθ!(data, marginals)\n",
    "        stepη!(data, marginals)\n",
    "        stepγ!(data, marginals)\n",
    "        stepξ!(data, marginals)\n",
    "#         stepz_tmin1!(data, marginals)\n",
    "    end\n",
    "\n",
    "    # Store current parameterizations of marginals\n",
    "    params_z[1][:,t] = unsafeMean(marginals[:z_t])\n",
    "    params_z[2][:,:,t] = marginals[:z_t].params[:w]\n",
    "    params_θ[1][:,t] = unsafeMean(marginals[:θ])\n",
    "    params_θ[2][:,:,t] = marginals[:θ].params[:w]\n",
    "    params_η[1][1,t] = unsafeMean(marginals[:η])\n",
    "    params_η[2][1,t] = marginals[:η].params[:w]\n",
    "    params_γ[1][1,t] = marginals[:γ].params[:a]\n",
    "    params_γ[2][1,t] = marginals[:γ].params[:b]\n",
    "    params_ξ[1][1,t] = marginals[:ξ].params[:a]\n",
    "    params_ξ[2][1,t] = marginals[:ξ].params[:b]\n",
    "    \n",
    "    \"Forecast several steps ahead\"\n",
    "    \n",
    "    if T_ > 2\n",
    "    \n",
    "        params_zpred_lar[1][:,t,1] = params_z[1][:,t]\n",
    "        params_zpred_lar[2][:,:,t,1] = params_z[2][:,:,t]\n",
    "\n",
    "        for tt = 1:TT\n",
    "\n",
    "            # Initialize marginals\n",
    "            marginals[:z_pred_tmin1] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_zpred_lar[1][:,t,tt], w=params_zpred_lar[2][:,:,t,tt])\n",
    "            marginals[:z_pred_t] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_zpred_lar[1][:,t,tt], w=params_zpred_lar[2][:,:,t,tt])\n",
    "\n",
    "            data = Dict(:u_t => input_[t+tt],\n",
    "                        :m_z => params_zpred_lar[1][:,t,tt],\n",
    "                        :w_z => params_zpred_lar[2][:,:,t,tt],\n",
    "                        :θ => params_θ[1][:,t],\n",
    "                        :η => params_η[1][t],\n",
    "                        :γ => params_γ[1][t]/params_γ[2][t])\n",
    "\n",
    "            # Iterate variational parameter updates\n",
    "            for i = 1:num_iterations\n",
    "                stepz_pred_t!(data, marginals)\n",
    "        #             stepz_pred_tmin1!(data, marginals)\n",
    "            end\n",
    "\n",
    "            # Store current parameterizations of marginals\n",
    "            params_zpred_lar[1][:,t,tt+1] = unsafeMean(marginals[:z_pred_t])\n",
    "            params_zpred_lar[2][:,:,t,tt+1] = marginals[:z_pred_t].params[:w]\n",
    "\n",
    "        end\n",
    "\n",
    "        # Evaluate prediction error for forecast\n",
    "        pred_diff_lar[t,:] = (params_zpred_lar[1][1,t,2:end] .- output_[t+1:t+TT])\n",
    "        pred_pwerr_lar[t,:] = params_zpred_lar[2][1,1,t,2:end].*(params_zpred_lar[1][1,t,2:end] .- output_[t+1:t+TT]).^2\n",
    "\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a time-point and visualize forecasting\n",
    "t = 9000\n",
    "\n",
    "# Mean and std dev of predictions\n",
    "zpred_lar_mean = params_zpred_lar[1][1,t,2:TT+1]\n",
    "zpred_lar_std = sqrt.(inv.(params_zpred_lar[2][1,1,t,2:TT+1])) \n",
    "\n",
    "\n",
    "scatter(output_[t+1:t+TT], label=\"observations\", xlabel=\"time-steps ahead\")\n",
    "plot!(zpred_lar_mean, ribbon=[zpred_lar_std, zpred_lar_std], label=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a number of steps ahead\n",
    "tt = 2\n",
    "\n",
    "# Extract mean of state marginals\n",
    "estimated_states_lar = params_zpred_lar[1][1,:,tt]\n",
    "\n",
    "# Plot every n-th time-point to avoid figure size exploding\n",
    "n = 100\n",
    "\n",
    "p23 = Plots.scatter(output_[1:n:end], color=\"black\", label=\"output\", markersize=2, size=(800,400), xlabel=\"time (t)\", ylabel=\"response\", legend=:bottomleft)\n",
    "Plots.plot!(estimated_states_lar[1:n:end], color=\"red\", linewidth=1, label=\"estimated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(p23, \"viz/forecasted-states-lar_\"*string(tt)*\"stepahead.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines - random walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System identification graph\n",
    "graph5 = FactorGraph()\n",
    "\n",
    "# Static parameters\n",
    "θ = [1.0, 0.0]\n",
    "η = 1.0\n",
    "γ = params_γ[1][end]./params_γ[2][end]\n",
    "ξ = params_ξ[1][end]./params_ξ[2][end]\n",
    "\n",
    "# State prior\n",
    "@RV z_rw ~ GaussianMeanPrecision(placeholder(:m_z, dims=(2,)), placeholder(:w_z, dims=(2, 2)), id=:z_t)\n",
    "\n",
    "# Autoregressive node\n",
    "@RV x_rw ~ AutoregressiveControl(θ, z_rw, η, placeholder(:u_t), γ, id=:x_t)\n",
    "\n",
    "# Specify likelihood\n",
    "@RV y_t ~ GaussianMeanPrecision(dot([1. , 0.], x_rw), ξ, id=:y_t)\n",
    "\n",
    "# Placeholder for observation\n",
    "placeholder(y_t, :y_t)\n",
    "\n",
    "# Draw time-slice subgraph\n",
    "ForneyLab.draw(graph5)\n",
    "\n",
    "# Inference algorithm\n",
    "q5 = PosteriorFactorization(z_rw, x_rw, ids=[:z_rw, :x_rw])\n",
    "algo5 = variationalAlgorithm(q5, free_energy=false)\n",
    "source_code5 = algorithmSourceCode(algo5, free_energy=false)\n",
    "eval(Meta.parse(source_code5));\n",
    "# println(source_code5)\n",
    "\n",
    "# Forecasting graph\n",
    "graph6 = FactorGraph()\n",
    "\n",
    "# State prior\n",
    "@RV z_pred_rw ~ GaussianMeanPrecision(placeholder(:m_z, dims=(2,)), placeholder(:w_z, dims=(2, 2)), id=:z_t)\n",
    "\n",
    "# Autoregressive node\n",
    "@RV x_pred_rw ~ AutoregressiveControl(θ, z_pred_rw, η, placeholder(:u_t), γ, id=:x_t)\n",
    "\n",
    "# Draw time-slice subgraph\n",
    "ForneyLab.draw(graph6)\n",
    "\n",
    "# Inference algorithm\n",
    "q6 = PosteriorFactorization(z_pred_rw, x_pred_rw, ids=[:z_pred_rw, :x_pred_rw])\n",
    "algo6 = variationalAlgorithm(q6, free_energy=false)\n",
    "source_code6 = algorithmSourceCode(algo6, free_energy=false)\n",
    "eval(Meta.parse(source_code6));\n",
    "# println(source_code6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of steps ahead\n",
    "TT = 10\n",
    "\n",
    "# Inference parameters\n",
    "num_iterations = 10\n",
    "\n",
    "# Initialize marginal distribution and observed data dictionaries\n",
    "data = Dict()\n",
    "marginals = Dict()\n",
    "\n",
    "# Initialize arrays of parameterizations\n",
    "params_z = (zeros(2,T_ - TT), repeat(.1 .*float(eye(2)), outer=(1,1,T_ - TT)))\n",
    "\n",
    "# Initialize future state arrays\n",
    "params_zpred_rw = (zeros(2, T_ - TT, TT+1), repeat(.1 .*float(eye(2)), outer=(1,1,T_ - TT, TT+1)))\n",
    "pred_diff_rw = zeros(T_ - TT, TT)\n",
    "pred_pwerr_rw = zeros(T_ - TT, TT)\n",
    "\n",
    "# Start progress bar\n",
    "p = Progress(T_ - TT, 1, \"At time \")\n",
    "\n",
    "# Perform inference at each time-step\n",
    "for t = 2:(T_ - TT)\n",
    "\n",
    "    # Update progress bar\n",
    "    update!(p, t)\n",
    "    \n",
    "    \"Filtering\"\n",
    "\n",
    "    # Initialize marginals\n",
    "    marginals[:x_rw] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_z[1][:,t-1], w=params_z[2][:,:,t-1])\n",
    "    marginals[:z_rw] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_z[1][:,t-1], w=params_z[2][:,:,t-1])\n",
    "    \n",
    "    data = Dict(:y_t => output_[t],\n",
    "                :u_t => input_[t],\n",
    "                :m_z => params_z[1][:,t-1],\n",
    "                :w_z => params_z[2][:,:,t-1])\n",
    "\n",
    "    # Iterate variational parameter updates\n",
    "    for i = 1:num_iterations\n",
    "\n",
    "        stepx_rw!(data, marginals)\n",
    "    #         stepz!(data, marginals)\n",
    "    end\n",
    "\n",
    "    # Store current parameterizations of marginals\n",
    "    params_z[1][:,t] = unsafeMean(marginals[:x_rw])\n",
    "    params_z[2][:,:,t] = marginals[:x_rw].params[:w]\n",
    "    \n",
    "    \"Forecast several steps ahead\"\n",
    "    \n",
    "    if T_ > 2\n",
    "    \n",
    "        params_zpred_rw[1][:,t,1] = params_z[1][:,t]\n",
    "        params_zpred_rw[2][:,:,t,1] = params_z[2][:,:,t]\n",
    "\n",
    "        for tt = 1:TT\n",
    "\n",
    "            # Initialize marginals\n",
    "            marginals[:x_pred_rw] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_zpred_rw[1][:,t,tt], w=params_zpred_rw[2][:,:,t,tt])\n",
    "            marginals[:z_pred_rw] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_zpred_rw[1][:,t,tt], w=params_zpred_rw[2][:,:,t,tt])\n",
    "\n",
    "            data = Dict(:u_t => input_[t+tt],\n",
    "                        :m_z => params_zpred_rw[1][:,t,tt],\n",
    "                        :w_z => params_zpred_rw[2][:,:,t,tt])\n",
    "\n",
    "            # Iterate variational parameter updates\n",
    "            for i = 1:num_iterations\n",
    "                stepx_pred_rw!(data, marginals)\n",
    "        #             stepz_pred!(data, marginals)\n",
    "            end\n",
    "\n",
    "            # Store current parameterizations of marginals\n",
    "            params_zpred_rw[1][:,t,tt+1] = unsafeMean(marginals[:x_pred_rw])\n",
    "            params_zpred_rw[2][:,:,t,tt+1] = marginals[:x_pred_rw].params[:w]\n",
    "\n",
    "        end\n",
    "\n",
    "        # Evaluate prediction error for forecast\n",
    "        pred_diff_rw[t,:] = (params_zpred_rw[1][1,t,2:end] .- output_[t+1:t+TT])\n",
    "        pred_pwerr_rw[t,:] = params_zpred_rw[2][1,1,t,2:end].*(params_zpred_rw[1][1,t,2:end] .- output_[t+1:t+TT]).^2\n",
    "\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize forecasting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a time-point and visualize forecasting\n",
    "t = 9000\n",
    "\n",
    "# Mean and std dev of predictions\n",
    "zpred_rw_mean = params_zpred_rw[1][1,t,2:TT+1]\n",
    "zpred_rw_std = sqrt.(inv.(params_zpred_rw[2][1,1,t,2:TT+1])) \n",
    "\n",
    "\n",
    "scatter(output_[t+1:t+TT], label=\"observations\", xlabel=\"time-steps ahead\")\n",
    "plot!(zpred_rw_mean, ribbon=[zpred_rw_std, zpred_rw_std], label=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of state marginals\n",
    "estimated_states_rw = params_zpred_rw[1][1,:,9]\n",
    "\n",
    "# Plot every n-th time-point to avoid figure size exploding\n",
    "n = 100\n",
    "\n",
    "p3 = Plots.scatter(output_[1:n:end], color=\"black\", label=\"output\", markersize=2, size=(800,400), xlabel=\"time (t)\", ylabel=\"response\", legend=:topleft)\n",
    "Plots.plot!(estimated_states_rw[1:n:end], color=\"red\", linewidth=1, label=\"estimated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize performance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_rw = zeros(TT,)\n",
    "RMSE_lar = zeros(TT,)\n",
    "RMSE_nar = zeros(TT,)\n",
    "\n",
    "ix = 20000:67390\n",
    "\n",
    "for tt = 1:TT\n",
    "\n",
    "    # Compute RMSE for each step ahead\n",
    "    RMSE_rw[tt] = sqrt.(mean((params_zpred_rw[1][1,ix,1+tt] .- output_[ix]).^2))\n",
    "    RMSE_lar[tt] = sqrt.(mean((params_zpred_lar[1][1,ix,1+tt] .- output_[ix]).^2))\n",
    "    RMSE_nar[tt] = sqrt.(mean((params_zpred_nar[1][1,ix,1+tt] .- output_[ix]).^2))\n",
    "    \n",
    "end\n",
    "\n",
    "p110 = plot(1:TT, RMSE_nar, color=\"red\", label=\"NAR\", size=(600,400))\n",
    "plot!(1:TT, RMSE_lar, color=\"blue\", label=\"LAR\", size=(600,400))\n",
    "plot!(1:TT, RMSE_rw, color=\"green\", label=\"RW\", size=(600,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(p110, \"viz/RMSE_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 10:87390\n",
    "\n",
    "mpwerr_lar = mean(pred_pwerr_lar[ix,:], dims=1)' \n",
    "spwerr_lar = sqrt.(var(pred_pwerr_lar[ix,:], dims=1)') ./length(ix)\n",
    "mpwerr_nar = mean(pred_pwerr_nar[ix,:], dims=1)' \n",
    "spwerr_nar = sqrt.(var(pred_pwerr_nar[ix,:], dims=1)') ./ length(ix)\n",
    "\n",
    "# p110 = plot(1:TT, mpwerr_nar, color=\"red\", label=\"nonlin-AR\")\n",
    "p110 = plot(1:TT, mpwerr_nar, ribbon=[spwerr_nar, spwerr_nar], fillalpha=0.3, color=\"red\", label=\"nonlin-AR\")\n",
    "# plot!(1:TT, mpwerr_lar, color=\"blue\", label=\"linear-AR\", linestyle=:dashdot)\n",
    "plot!(1:TT, mpwerr_lar, ribbon=[spwerr_lar, spwerr_lar], fillalpha=0.3, label=\"linear-AR\", linestyle=:dashdot, color=\"blue\", size=(600,300), ylim=[0., 1.], legend=:topleft, tickfontsize=12, xlabel=\"+k steps ahead\", ylabel=\"avg weighted pred. error\", legendfontsize=12, guidefontsize=14)\n",
    "# plot!(1:TT, mpwerr_rw, color=\"green\", label=\"RW\", size=(600,400), ylim=[0., 1.], legend=:topleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(p110, \"viz/mpwerr_comparison.png\")\n",
    "savefig(p110, \"viz/mpwerr_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subsampling\n",
    "ss = 100\n",
    "\n",
    "# Select a number of time-steps ahead\n",
    "tt = 10\n",
    "\n",
    "# Index performance metrics\n",
    "pwerr_rw_tt = pred_pwerr_rw[10:ss:end,tt]\n",
    "pwerr_lar_tt = pred_pwerr_lar[10:ss:end,tt]\n",
    "pwerr_nar_tt = pred_pwerr_nar[10:ss:end,tt]\n",
    "\n",
    "# Plot mean difference for all time\n",
    "# plot(pwerr_rw_tt, color=\"green\", label=\"RW\", markersize=2, size=(600,400), xlabel=\"time (t)\", ylabel=\"precision-weighted prediction error\")\n",
    "plot(pwerr_lar_tt, color=\"blue\", label=\"LAR\", markersize=2, size=(600,300), xlabel=\"time (t)\", ylabel=\"prec.-weighted pred. error\")\n",
    "plot!(pwerr_nar_tt, color=\"red\", label=\"NAR\", markersize=2, size=(600,300), ylim=[0., 4.], legend=:topleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a time-point and visualize forecasting\n",
    "t = 87200\n",
    "\n",
    "xticks = [string(t)*\"+1\", string(t)*\"+2\"]\n",
    "\n",
    "# Mean and std dev of predictions\n",
    "zpred_nar_mean = params_zpred_nar[1][1,t,2:TT+1]\n",
    "zpred_nar_std = sqrt.(inv.(params_zpred_nar[2][1,1,t,2:TT+1])) \n",
    "zpred_lar_mean = params_zpred_lar[1][1,t,2:TT+1]\n",
    "zpred_lar_std = sqrt.(inv.(params_zpred_lar[2][1,1,t,2:TT+1])) \n",
    "\n",
    "\n",
    "p224 = scatter(output_[t+1:t+TT], label=\"observations\", color=\"black\", xlabel=\"t=\"*string(t+40101)*\"  + k steps ahead\")\n",
    "plot!(zpred_nar_mean, ribbon=[zpred_nar_std, zpred_nar_std], fillalpha=0.3, color=\"red\", label=\"pred. nonlin-AR\")\n",
    "plot!(zpred_lar_mean, ribbon=[zpred_lar_std, zpred_lar_std], fillalpha=0.3, color=\"blue\", linestyle=:dashdot, label=\"pred. linear-AR\", size=(600,300), tickfontsize=12, legendfontsize=10, legend=:topleft, ylabel=\"signal\", guidefontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(p224, \"viz/example-forecast-comparison.png\")\n",
    "savefig(p224, \"viz/example-forecast-comparison.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
