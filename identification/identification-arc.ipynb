{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silverbox\n",
    "\n",
    "Silverbox refers to one of the nonlinear system identification benchmarks on http://nonlinearbenchmark.org/#Silverbox. \n",
    "It is a simulation of a [Duffing oscillator](https://en.wikipedia.org/wiki/Duffing_equation), ocurring for instance in nonlinear spring pendulums.\n",
    "\n",
    "State-space model description of the system:\n",
    "\n",
    "$$\\begin{align}\n",
    "m \\frac{d^2 x(t)}{dt^2} + v \\frac{d x(t)}{dt} + a x(t) + b x^3(t) =&\\ u(t) + w(t) \\\\\n",
    "y(t) =&\\ x(t) + e(t)\n",
    "\\end{align}$$\n",
    "\n",
    "where\n",
    "$$\\begin{align}\n",
    "m     =&\\ \\text{mass} \\\\\n",
    "v     =&\\ \\text{viscous damping} \\\\\n",
    "a     =&\\ \\text{linear stiffness} \\\\\n",
    "b     =&\\ \\text{nonlinear stiffness} \\\\\n",
    "y(t)    =&\\ \\text{observation (displacement)} \\\\\n",
    "x(t)    =&\\ \\text{state (displacement)} \\\\\n",
    "u(t)    =&\\ \\text{force} \\\\\n",
    "e(t)    =&\\ \\text{measurement noise} \\\\\n",
    "w(t)    =&\\ \\text{process noise}\n",
    "\\end{align}$$\n",
    "\n",
    "The process noise is a Wiener process, where the increment is Gaussian distributed $w(t) = \\frac{d B(t)}{dt} \\sim \\mathcal{N}(0, \\tau^{-1}dt)$. The parameter $\\tau$ represents the precision of the process. The same holds for the measurement noise.\n",
    "\n",
    "## Solution steps\n",
    "\n",
    "### 1. Discretize\n",
    "\n",
    "I'm now using a central difference for the second derivative and a forward difference for the first derivative:\n",
    "\n",
    "$$\\begin{align}\n",
    "x''(t) \\approx&\\ \\frac{x(t+h) - 2x(t) + x(t-h)}{h^2} = \\frac{x_{t+1} - 2x_{t} + x_{t-1}}{(\\Delta t)^2}\\\\\n",
    "x'(t) \\approx&\\ \\frac{x(t+h) - x(t)}{h} = \\frac{x_{t+1} - x_{t}}{\\Delta t}\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "where $\\Delta t = t - (t-1) = 1$. Let $w_t$ be a sample from $\\mathcal{N}(0, \\tau^{-1})$. The DE can now be written as the following discrete-time system:\n",
    "\n",
    "$$\\begin{align}\n",
    "m (x_{t+1} - 2x_{t} + x_{t-1}) + v (x_{t+1} - x_{t}) + a x_t + b x_t^3 =&\\ u_t + w_t\n",
    "\\end{align}$$\n",
    "\n",
    "Re-writing this as a function of $x_{t+1}$ yields:\n",
    "$$\\begin{align}\n",
    "(m + v) x_{t+1}&\\ + (-2m - v + a) x_{t} + bx_t^3 + m x_{t-1} = u_t + w_t \\\\\n",
    "% x_t + \\frac{-2m - v}{m + v + a} x_{t-1} + \\frac{m}{m + v + a} x_{t-2} =&\\ \\frac{1}{m + v + a} u_t + \\frac{1}{m + v + a} w_t \\\\\n",
    "x_{t+1}&\\ = \\frac{2m + v - a}{m + v} x_{t} + \\frac{-b}{m + v}x_t^3 + \\frac{-m}{m + v} x_{t-1} + \\frac{1}{m + v} u_t + \\frac{1}{m + v} w_t \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "### 2. Convert to multivariate first-order form\n",
    "\n",
    "I can cast the above system into matrix form:\n",
    "\n",
    "$$ \\underbrace{\\begin{bmatrix} x_{t+1} \\\\ x_{t} \\end{bmatrix}}_{z_t} = \\underbrace{\\begin{bmatrix} \\frac{2m+v-a}{m+v} - \\frac{b}{m+v}x_t^2 & \\frac{-m}{m+v} \\\\ 1 & 0 \\end{bmatrix} \\begin{bmatrix} x_{t} \\\\ x_{t-1} \\end{bmatrix}}_{A(\\theta, z_{t-1})} + \\begin{bmatrix} \\frac{1}{m+v} \\\\ 0 \\end{bmatrix} u_t + \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\tilde{w}_t \\, ,$$\n",
    "\n",
    "where $A(\\theta, z_{t-1}) = Sz_{t-1} + c g(z_{t-1}, \\theta)$ with the familiar shifting operator $S$ and selection variable $c$, $g(z_{t-1}, \\theta) = \\theta_1 x_t + \\theta_2 x_t^3 + \\theta_3 x_{t-1}$ and\n",
    "\n",
    "$$\\begin{align}\n",
    "\\theta_1 =&\\ \\frac{2m+v-a}{m+v} \\\\\n",
    "\\theta_2 =&\\ \\frac{-b}{m+v} \\\\\n",
    "\\theta_3 =&\\ \\frac{-m}{m+v} \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "Additionally, I'll introduce $\\eta = 1/(m+v)$. I can absorb $\\eta$ into $w_t$: $\\mathbb{V}[\\eta w_t] = \\eta^2 \\mathbb{V}[w_t] = \\eta^2 \\tau^{-1}$. I will rename $\\eta^2 \\tau^{-1}$ as $\\gamma^{-1}$ and let $\\tilde{w}_t \\sim \\mathcal{N}(0, \\gamma^{-1})$. In total, I have five unknowns $m,v,a,b,\\tau$ and five equations. We can solve the nonlinear system of equations to obtain estimates of the physical parameters from the shorthand parameters. The shorthands have the benefit that they allow for some freedom in choosing priors. The downside is that we lose the confidence estimate.\n",
    "\n",
    "The system is now a nonlinear autoregressive process:\n",
    "\n",
    "$$z_t = A(\\theta, z_{t-1}) + c\\eta u_t + \\tilde{w}_t$$\n",
    "\n",
    "Note that we need a two-dimensional state prior now (reminiscent of adding an initial condition on the velocity).\n",
    "\n",
    "### 3. Convert to Gaussian probability\n",
    "\n",
    "Integrating out $\\tilde{w}_t$ produces a Gaussian state transition node:\n",
    "\n",
    "$$z_t \\sim \\mathcal{N}(A(\\theta, z_{t-1}) + c\\eta u_t, V)$$\n",
    "\n",
    "where $V = \\begin{bmatrix} \\gamma^{-1} & 0 \\\\ 0 & \\epsilon \\end{bmatrix}$ and $V^{-1} = W = \\begin{bmatrix} \\gamma & 0 \\\\ 0 & 1/\\epsilon \\end{bmatrix}$.\n",
    "\n",
    "The observation likelihood maps to\n",
    "\n",
    "$$y_t \\sim \\mathcal{N}(c^{\\top} z_t, \\xi^{-1})$$\n",
    "\n",
    "where $e_t \\sim \\mathcal{N}(0, \\xi^{-1})$.\n",
    "\n",
    "### 6. Choose priors\n",
    "\n",
    "We currently have unknown parameters $\\psi = (\\theta_1, \\theta_2, \\theta_3, \\eta, \\gamma)$. Since they are substitutions, we don't know anything about their support directly. We do know about it indirectly, from the nonlinear combinations of the physical coefficients. We know that mass $m$ and process precision $\\gamma$ are strictly positive parameters and that the damping and stiffness coefficients can be both positive and negative. Hence, by examing the nonlinear transform $\\psi = G(\\phi)$;\n",
    "\n",
    "$$\\begin{align} \n",
    "\\theta_1 =&\\ \\frac{2m+v-a}{m+v} \\\\\n",
    "\\theta_2 =&\\ \\frac{-b}{m+v} \\\\\n",
    "\\theta_3 =&\\ \\frac{-m}{m+v} \\\\\n",
    "\\eta =&\\ \\frac{1}{m+v} \\\\\n",
    "\\gamma^{-1} =&\\ \\frac{1}{\\tau (m + v)^2} \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "we realize that $\\theta_1$, $\\theta_2$, $\\theta_3$ and $\\eta$ can be both positive and negative, but $\\gamma$ can only be positive. As such, we choose the following priors:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\theta \\sim&\\ \\text{Normal}(m^{0}_{\\theta}, V^{0}_{\\theta}) \\\\\n",
    "\\eta \\sim&\\ \\text{logNormal}(m^{0}_{\\eta}, v^{0}_{\\eta}) \\\\ \n",
    "\\gamma \\sim&\\ \\text{Gamma}(a^{0}_\\gamma, b^{0}_\\gamma) \n",
    "\\end{align}$$\n",
    "\n",
    "Modeling $\\theta = (\\theta_1, \\theta_2, \\theta_3)$ as a joint Gaussian allows for incorporating it into an Autoregressive node.\n",
    "\n",
    "### 7. Recover physical variables from substituted ones\n",
    "\n",
    "Since we have five equations and five unknowns, we can perfectly recover point estimates of the physical variables from substituted ones. However, we don't want point estimates, we want posteriors. \n",
    "\n",
    "If we approximate $\\gamma$ with a log-Normal distribution and then map it to a Gaussian distribution (i.e. model $\\tilde{\\gamma} = \\log(\\gamma)$), we end up with a Gaussian distributed random vector $\\psi = [\\theta_1, \\theta_2, \\theta_3, \\eta, \\tilde{\\gamma}]$. We can perform a Gaussian approximation of the inverse mapping $G^{-1}(\\psi)$ using a first-order Taylor expansion:\n",
    "\n",
    "$$\\begin{align}\n",
    "m_{\\phi} \\triangleq \\mathbb{E}[G^{-1}(\\psi)] =&\\ G^{-1}(m_{\\psi}) \\\\\n",
    "V_{\\phi} \\triangleq \\mathbb{V}[G^{-1}(\\psi)] =&\\ J_{\\psi}(m_{\\psi}) G^{-1}(m_{\\psi}) J_{\\psi}(m_{\\psi})^{\\top} \\, ,\n",
    "\\end{align}$$\n",
    "\n",
    "The inverse mapping has the form:\n",
    "\n",
    "$$\\begin{align} \n",
    "m =&\\ \\frac{-\\theta_3}{\\eta} \\\\\n",
    "v =&\\ \\frac{1+\\theta_3}{\\eta} \\\\\n",
    "a =&\\ \\frac{(1-\\theta_1 - \\theta_3)}{\\eta} \\\\\n",
    "b =&\\ \\frac{-\\theta_2}{\\eta} \\\\\n",
    "\\tau =&\\ \\tilde{\\gamma} \\eta^2 \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "The Jacobian can be obtained automatically using Julia packages such as ForwardDiff.jl or Zygote.jl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Let's first have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using CSV\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "viz = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV file\n",
    "df = CSV.read(\"../data/SNLS80mV.csv\", ignoreemptylines=true)\n",
    "df = select(df, [:V1, :V2])\n",
    "\n",
    "# Shorthand\n",
    "input = df[:,1]\n",
    "output = df[:,2]\n",
    "\n",
    "# Time horizon\n",
    "T = size(df, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot every n-th time-point to avoid figure size exploding\n",
    "n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if viz\n",
    "    p1a = Plots.plot(1:n:T, output[1:n:T], color=\"black\", label=\"\", markersize=2, xlabel=\"time (t)\", ylabel=\"output (displacement)\", size=(1200,400))    \n",
    "    Plots.savefig(p1a, \"viz/output_signal.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if viz\n",
    "    p2a = Plots.plot(1:n:T, input[1:n:T], color=\"black\", label=\"\", markersize=2, xlabel=\"time (t)\", ylabel=\"input (control)\", size=(1200,400))\n",
    "    Plots.savefig(p2a, \"viz/input_signal.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating parameters via Bayesian filtering\n",
    "\n",
    "Implementation with ForneyLab and ARC node. The ARC node is locally modified from the package LAR (https://github.com/biaslab/LAR/). It contains a AutoregressiveControl and AutoregressiveControlNL node, where a nonlinearity g can be provided as an argument.\n",
    "\n",
    "The major change from a linear ARC to a nonlinear ARC node is in working out the expectations for $g(x,\\theta)$ as opposed to $\\theta^{\\top}x$. There are a number of ways of doing this. I have chosen a first-order Taylor approximation:\n",
    "\n",
    "$$ g(x,\\theta) = g(m_x, m_{\\theta}) + J_{x}(m_x, m_{\\theta})^{\\top}(x - m_x) + J_{\\theta}(m_x, m_{\\theta})^{\\top}(\\theta - m_{\\theta}) \\, ,$$\n",
    "\n",
    "where $J_x$ denotes the partial derivative of $g$ with respect to $x$ and $J_{\\theta}$ w.r.t. $\\theta$. Note that our current $g$ is linear in $\\theta$ and you could argue that you don't need to approximate it. However, the first-order Taylor is exact in that case. The expectations are:\n",
    "\n",
    "#### First-order\n",
    "\n",
    "- W.r.t. both $x$ and $\\theta$:\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_{q(x),q(\\theta)}[ g(x,\\theta)] =&\\ \\mathbb{E}_{q(x),q(\\theta)}[ g(m_x, m_{\\theta}) + J_{x}(m_x, m_{\\theta})^{\\top}(x - m_x) + J_{\\theta}(m_x, m_{\\theta})^{\\top}(\\theta - m_{\\theta}) ] \\\\\n",
    "=&\\ g(m_x, m_{\\theta}) + J_{x}(m_x, m_{\\theta})^{\\top}\\underbrace{\\mathbb{E}_{q(x)}[(x - m_x)]}_{0} + J_{\\theta}(m_x, m_{\\theta})^{\\top}\\underbrace{\\mathbb{E}_{q(\\theta)}[(\\theta - m_{\\theta})]}_{0} \\\\\n",
    "=&\\ g(m_x, m_{\\theta}) \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "- W.r.t. $x$:\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_{q(x)}[ g(x,\\theta)] =&\\ \\mathbb{E}_{q(x)}[ g(m_x, m_{\\theta}) + J_{x}(m_x, m_{\\theta})^{\\top}(x - m_x) + J_{\\theta}(m_x, m_{\\theta})^{\\top}(\\theta - m_{\\theta}) ] \\\\\n",
    "=&\\ g(m_x, m_{\\theta}) + J_{x}(m_x, m_{\\theta})^{\\top}\\underbrace{\\mathbb{E}_{q(x)}[(x - m_x)]}_{0} + J_{\\theta}(m_x, m_{\\theta})^{\\top}(\\theta - m_{\\theta}) \\\\\n",
    "=&\\ g(m_x, m_{\\theta}) + J_{\\theta}(m_x, m_{\\theta})^{\\top}(\\theta - m_{\\theta}) \\\\\n",
    "\\propto&\\ J_{\\theta}(m_x, m_{\\theta})^{\\top}\\theta \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "- W.r.t. $\\theta$:\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_{q(x),q(\\theta)}[ g(x,\\theta)] =&\\ \\mathbb{E}_{q(x),q(\\theta)}[ g(m_x, m_{\\theta}) + J_{x}(m_x, m_{\\theta})^{\\top}(x - m_x) + J_{\\theta}(m_x, m_{\\theta})^{\\top}(\\theta - m_{\\theta}) ] \\\\\n",
    "=&\\ g(m_x, m_{\\theta}) + J_{x}(m_x, m_{\\theta})^{\\top}(x - m_x) + J_{\\theta}(m_x, m_{\\theta})^{\\top}\\underbrace{\\mathbb{E}_{q(\\theta)}[(\\theta - m_{\\theta})]}_{0} \\\\\n",
    "=&\\ g(m_x, m_{\\theta}) + J_{x}(m_x, m_{\\theta})^{\\top}(x - m_x) \\\\\n",
    "\\propto&\\ J_{x}(m_x, m_{\\theta})^{\\top}x \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "#### Second-order\n",
    "\n",
    "Shorthand: $g$ for $g(m_x, m_\\theta)$, $J_x$ for $J_x(m_x, m_{\\theta})$ and $J_{\\theta}(m_x, m_{\\theta})$.\n",
    "\n",
    "- W.r.t. both $x$ and $\\theta$:\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_{q(x),q(\\theta)}[ g(x,\\theta)^2] =&\\ \\mathbb{E}_{q(x),q(\\theta)}[ \\big( g + J_{x}^{\\top}(x - m_x) + J_{\\theta}^{\\top}(\\theta - m_{\\theta}) \\big)^2] \\\\\n",
    "=&\\ g^{2} + 2 g J_{x}^{\\top}\\underbrace{\\mathbb{E}_{q(x)}[(x - m_x)]}_{0}  + 2 g J_{\\theta}^{\\top}\\underbrace{\\mathbb{E}_{q(\\theta)}[(\\theta - m_{\\theta})]}_{0} + 2 J_{x}^{\\top}\\underbrace{\\mathbb{E}_{q(x)}[(x - m_x)]}_{0} J_{\\theta}^{\\top}\\underbrace{\\mathbb{E}_{q(\\theta)}[(\\theta - m_{\\theta})]}_{0} \\\\\n",
    "&\\ + J_x^{\\top}\\mathbb{E}_{q(x)}[(x - m_x)(x - m_x)^{\\top}]J_x + J_{\\theta}^{\\top}\\mathbb{E}_{q(\\theta)}[(\\theta - m_{\\theta})(\\theta - m_{\\theta})^{\\top}] J_{\\theta} \\\\\n",
    "=&\\ g^{2} + J_x^{\\top} V_x J_x + J_{\\theta}^{\\top} V_{\\theta} J_{\\theta} \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "- W.r.t. $x$:\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_{q(x)}[ g(x,\\theta)^2] =&\\ \\mathbb{E}_{q(x)}[ \\big( g + J_{x}^{\\top}(x - m_x) + J_{\\theta}^{\\top}(\\theta - m_{\\theta}) \\big)^2] \\\\\n",
    "=&\\ g^{2} + 2 g J_{x}^{\\top}\\underbrace{\\mathbb{E}_{q(x)}[(x - m_x)]}_{0}  + 2 g J_{\\theta}^{\\top}(\\theta - m_{\\theta}) + 2 J_{x}^{\\top}\\underbrace{\\mathbb{E}_{q(x)}[(x - m_x)]}_{0} J_{\\theta}^{\\top}(\\theta - m_{\\theta}) \\\\\n",
    "&\\ + J_x^{\\top}\\mathbb{E}_{q(x)}[(x - m_x)(x - m_x)^{\\top}]J_x + J_{\\theta}^{\\top}(\\theta - m_{\\theta})(\\theta - m_{\\theta})^{\\top} J_{\\theta} \\\\\n",
    "=&\\ g^{2} + 2 g J_{\\theta}^{\\top}(\\theta - m_{\\theta}) + J_{\\theta}^{\\top} V_{\\theta} J_{\\theta} + J_x^{\\top} V_x J_x \\\\\n",
    "\\propto&\\ (g-J_{\\theta}^{\\top}m_{\\theta}) J_{\\theta}^{\\top}\\theta + \\theta^{\\top}J_{\\theta}(g - J_{\\theta}^{\\top}m_{\\theta}) + \\theta^{\\top} J_{\\theta} J_{\\theta}^{\\top} \\theta \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "- W.r.t. $\\theta$:\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_{q(\\theta)}[ g(x,\\theta)^2] =&\\ \\mathbb{E}_{q(\\theta)}[ \\big( g + J_{x}^{\\top}(x - m_x) + J_{\\theta}^{\\top}(\\theta - m_{\\theta}) \\big)\\big(\\dots \\big)^{\\top}] \\\\\n",
    "=&\\ g^{2} + 2 g J_{x}^{\\top}(x - m_x)  + 2 g J_{\\theta}^{\\top}\\underbrace{\\mathbb{E}_{q(\\theta)}[(\\theta - m_{\\theta})]}_{0} + 2 J_{x}^{\\top}(x - m_x) J_{\\theta}^{\\top}\\underbrace{\\mathbb{E}_{q(\\theta)}[(\\theta - m_{\\theta})]}_{0} \\\\\n",
    "&\\ + J_x^{\\top}(x - m_x)(x - m_x)^{\\top}J_x + J_{\\theta}^{\\top}\\mathbb{E}_{q(\\theta)}[(\\theta - m_{\\theta})(\\theta - m_{\\theta})^{\\top}] J_{\\theta} \\\\\n",
    "=&\\ g^{2} + 2 g J_{x}^{\\top}(x - m_x) + J_x^{\\top} (x - m_x)(x - m_x)^{\\top} J_x + J_{\\theta}^{\\top} V_{\\theta} J_{\\theta} \\\\\n",
    "\\propto&\\ (g-J_x^{\\top}m_x) J_x^{\\top}x + x^{\\top}J_x(g - J_x^{\\top}m_x) + x^{\\top} J_x J_x^{\\top} x \\, .\n",
    "\\end{align}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using ForneyLab\n",
    "using ForneyLab: unsafeMean, unsafeCov, unsafeVar, unsafePrecision\n",
    "using ProgressMeter\n",
    "\n",
    "include(\"../ARC-node/ARC.jl\")\n",
    "using .ARC.Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote\n",
    "\n",
    "function Jacobian(F, x)\n",
    "    y = F(x)\n",
    "    n = length(y)\n",
    "    m = length(x)\n",
    "    T = eltype(y)\n",
    "    j = Array{T, 2}(undef, n, m)\n",
    "    for i in 1:n\n",
    "        j[i, :] .= gradient(x -> F(x)[i], x)[1]\n",
    "    end\n",
    "    return j\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start graph\n",
    "graph = FactorGraph()\n",
    "\n",
    "# Static parameters\n",
    "@RV θ ~ GaussianMeanPrecision(placeholder(:m_θ, dims=(3,)), placeholder(:w_θ, dims=(3,3)))\n",
    "@RV η ~ LogNormal(placeholder(:m_η), placeholder(:s_η))\n",
    "@RV γ ~ Gamma(placeholder(:a_γ), placeholder(:b_γ))\n",
    "@RV ξ ~ Gamma(placeholder(:a_ξ), placeholder(:b_ξ))\n",
    "\n",
    "# Nonlinearity\n",
    "g(x,θ) = θ[1]*x[1] + θ[2]*x[1]^3 + θ[3]*x[2]\n",
    "\n",
    "# State prior\n",
    "@RV z_t ~ GaussianMeanPrecision(placeholder(:m_z, dims=(2,)), placeholder(:w_z, dims=(2, 2)), id=:z_t)\n",
    "\n",
    "# Autoregressive node\n",
    "@RV x_t ~ AutoregressiveControlNL(θ, z_t, η, placeholder(:u_t), γ, g=g, id=:x_t)\n",
    "\n",
    "# Specify likelihood\n",
    "@RV y_t ~ GaussianMeanPrecision(dot([1. , 0.], x_t), ξ, id=:y_t)\n",
    "\n",
    "# Placeholder for observation\n",
    "placeholder(y_t, :y_t)\n",
    "\n",
    "# Draw time-slice subgraph\n",
    "ForneyLab.draw(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer an algorithm\n",
    "q = PosteriorFactorization(z_t, x_t, θ, η, γ, ξ, ids=[:z, :x, :θ, :η, :γ, :ξ])\n",
    "algo = variationalAlgorithm(q, free_energy=false)\n",
    "source_code = algorithmSourceCode(algo, free_energy=false)\n",
    "eval(Meta.parse(source_code));\n",
    "println(source_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at only the first few timepoints\n",
    "# T = 10000\n",
    "T = size(df, 1);\n",
    "\n",
    "# Inference parameters\n",
    "num_iterations = 10\n",
    "\n",
    "# Initialize marginal distribution and observed data dictionaries\n",
    "data = Dict()\n",
    "marginals = Dict()\n",
    "\n",
    "# Initialize arrays of parameterizations\n",
    "params_x = (zeros(2,T+1), repeat(.1 .*float(eye(2)), outer=(1,1,T+1)))\n",
    "params_θ = (ones(3,T+1), repeat(.1 .*float(eye(3)), outer=(1,1,T+1)))\n",
    "params_η = (ones(1,T+1), .1*ones(1,T+1))\n",
    "params_γ = (1. *ones(1,T+1), 1. *ones(1,T+1))\n",
    "params_ξ = (1. *ones(1,T+1), 1. *ones(1,T+1))\n",
    "\n",
    "# Initialize physical coefficient estimate arrays\n",
    "params_ϕ = (zeros(5,T), zeros(5,5,T))\n",
    "params_ψ = (zeros(5,T), zeros(5,5,T))\n",
    "params_m = (zeros(T,), zeros(T,))\n",
    "params_v = (zeros(T,), zeros(T,))\n",
    "params_a = (zeros(T,), zeros(T,))\n",
    "params_b = (zeros(T,), zeros(T,))\n",
    "params_τ = (zeros(T,), zeros(T,))\n",
    "\n",
    "# Transformations between physical and substituted variables: ψ = G(ϕ) => ϕ = G_inv(ψ)\n",
    "G(ϕ) = [(2*ϕ[1] + ϕ[2] - ϕ[3])/(ϕ[1]+ϕ[2]), -ϕ[4]/(ϕ[1]+ϕ[2]), -ϕ[1]/(ϕ[1]+ϕ[2]), 1/(ϕ[1]+ϕ[2]), ϕ[5]*(ϕ[1]+ϕ[2])^2]\n",
    "G_inv(ψ) = [-ψ[3]/ψ[4], (1+ψ[3])/ψ[4], (1 - ψ[1] - ψ[3])/ψ[4], -ψ[2]/ψ[4], ψ[5]*ψ[4]^2]\n",
    "\n",
    "# Start progress bar\n",
    "p = Progress(T, 1, \"At time \")\n",
    "\n",
    "# Perform inference at each time-step\n",
    "for t = 1:T\n",
    "\n",
    "    # Update progress bar\n",
    "    update!(p, t)\n",
    "    \n",
    "    \"Filtering\"\n",
    "\n",
    "    # Initialize marginals\n",
    "    marginals[:x_t] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_x[1][:,t], w=params_x[2][:,:,t])\n",
    "    marginals[:z_t] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_x[1][:,t], w=params_x[2][:,:,t])\n",
    "    marginals[:θ] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_θ[1][:,t], w=params_θ[2][:,:,t])\n",
    "    marginals[:η] = ProbabilityDistribution(Univariate, LogNormal, m=params_η[1][1,t], s=params_η[2][1,t])\n",
    "    marginals[:γ] = ProbabilityDistribution(Univariate, Gamma, a=params_γ[1][1,t], b=params_γ[2][1,t])\n",
    "    marginals[:ξ] = ProbabilityDistribution(Univariate, Gamma, a=params_ξ[1][1,t], b=params_ξ[2][1,t])\n",
    "    \n",
    "    data = Dict(:y_t => output[t],\n",
    "                :u_t => input[t],\n",
    "                :m_z => params_x[1][:,t],\n",
    "                :w_z => params_x[2][:,:,t],\n",
    "                :m_θ => params_θ[1][:,t],\n",
    "                :w_θ => params_θ[2][:,:,t],\n",
    "                :m_η => params_η[1][1,t],\n",
    "                :s_η => params_η[2][1,t],\n",
    "                :a_γ => params_γ[1][1,t],\n",
    "                :b_γ => params_γ[2][1,t],\n",
    "                :a_ξ => params_ξ[1][1,t],\n",
    "                :b_ξ => params_ξ[2][1,t])\n",
    "\n",
    "    # Iterate variational parameter updates\n",
    "    for i = 1:num_iterations\n",
    "\n",
    "        stepx!(data, marginals)\n",
    "        stepθ!(data, marginals)\n",
    "        stepη!(data, marginals)\n",
    "        stepγ!(data, marginals)\n",
    "        stepξ!(data, marginals)\n",
    "    end\n",
    "\n",
    "    # Store current parameterizations of marginals\n",
    "    params_x[1][:,t+1] = unsafeMean(marginals[:x_t])\n",
    "    params_x[2][:,:,t+1] = marginals[:x_t].params[:w]\n",
    "    params_θ[1][:,t+1] = unsafeMean(marginals[:θ])\n",
    "    params_θ[2][:,:,t+1] = marginals[:θ].params[:w]\n",
    "    params_η[1][1,t+1] = marginals[:η].params[:m]\n",
    "    params_η[2][1,t+1] = marginals[:η].params[:s]\n",
    "    params_γ[1][1,t+1] = marginals[:γ].params[:a]\n",
    "    params_γ[2][1,t+1] = marginals[:γ].params[:b]\n",
    "    params_ξ[1][1,t+1] = marginals[:ξ].params[:a]\n",
    "    params_ξ[2][1,t+1] = marginals[:ξ].params[:b]\n",
    "    \n",
    "    \"Map substituted to physical variables via first-order Taylor\"\n",
    "    \n",
    "    # Approximate gamma with log-normal via moment-matching\n",
    "    Eγ = unsafeMean(marginals[:γ])\n",
    "    Vγ = unsafeVar(marginals[:γ])\n",
    "    m_γ = log(Eγ^2/sqrt(Vγ + Eγ^2))\n",
    "    v_γ = log(Vγ/Eγ^2 + 1)\n",
    "\n",
    "    # Construct vector of parameter estimates ψ\n",
    "    m_ψ = [unsafeMean(marginals[:θ])[1], unsafeMean(marginals[:θ])[2], unsafeMean(marginals[:θ])[3], unsafeMean(marginals[:η])[1], m_γ]\n",
    "    V_ψ = [unsafeCov(marginals[:θ]) zeros(3,2); zeros(2,3) [unsafeCov(marginals[:η])[1,1] 0;0 v_γ]]\n",
    "    \n",
    "    # Compute Jacobian of transformation \n",
    "    J_ψ = Jacobian(G_inv, m_ψ)\n",
    "    \n",
    "    # Compute moments of transformed Gaussian using first-order Taylor approx\n",
    "    m_ϕ = G_inv(m_ψ)\n",
    "    V_ϕ = J_ψ*V_ψ*J_ψ'\n",
    "\n",
    "    # Split ϕ into physical coefficients\n",
    "    m_m, m_v, m_a, m_b, m_τ = m_ϕ\n",
    "    v_m, v_v, v_a, v_b, v_τ = Diagonal(V_ϕ)\n",
    "    \n",
    "    # Store param estimates for mass\n",
    "    params_m[1][t] = m_m\n",
    "    params_m[2][t] = v_m\n",
    "    \n",
    "    # Store param estimates for friction\n",
    "    params_v[1][t] = m_v\n",
    "    params_v[2][t] = v_v\n",
    "    \n",
    "    # Store param estimates for linear stiffness\n",
    "    params_a[1][t] = m_a\n",
    "    params_a[2][t] = v_a\n",
    "    \n",
    "    # Store param estimates for nonlinear stiffness\n",
    "    params_b[1][t] = m_b\n",
    "    params_b[2][t] = v_b\n",
    "    \n",
    "    # Store param estimates for process precision\n",
    "    params_τ[1][t] = m_τ\n",
    "    params_τ[2][t] = v_τ\n",
    "    \n",
    "    # Store original parameters as well\n",
    "    params_ϕ[1][:,t] = m_ϕ\n",
    "    params_ϕ[2][:,:,t] = V_ϕ\n",
    "    params_ψ[1][:,t] = m_ψ\n",
    "    params_ψ[2][:,:,t] = V_ψ\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of state marginals\n",
    "estimated_states = params_x[1][1,2:end]\n",
    "\n",
    "if viz\n",
    "    # Plot every n-th time-point to avoid figure size exploding\n",
    "    n = 50\n",
    "    p1 = Plots.scatter(1:n:T, output[1:n:T], color=\"black\", label=\"output\", markersize=2, size=(1200,600), xlabel=\"time (t)\", ylabel=\"response\")\n",
    "    Plots.plot!(1:n:T, estimated_states[1:n:T], color=\"red\", linewidth=1, label=\"estimated\")\n",
    "#     Plots.savefig(p1, \"viz/nonlin_estimated_states01.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of coefficient marginals\n",
    "estimated_θ1_mean = params_θ[1][1,2:end]\n",
    "estimated_θ2_mean = params_θ[1][2,2:end]\n",
    "estimated_θ3_mean = params_θ[1][3,2:end]\n",
    "estimated_θ1_std = sqrt.(inv.(params_θ[2][1,1,2:end]))\n",
    "estimated_θ2_std = sqrt.(inv.(params_θ[2][2,2,2:end]))\n",
    "estimated_θ3_std = sqrt.(inv.(params_θ[2][3,3,2:end]))\n",
    "\n",
    "if viz\n",
    "    \n",
    "    # Plot both coefficients next to each other\n",
    "    p2a = Plots.plot(1:n:T, estimated_θ1_mean[1:n:T], ribbon=[estimated_θ1_std[1:n:T], estimated_θ1_std[1:n:T]], color=\"red\", label=\"θ_1\", xlabel=\"time (t)\")\n",
    "    p2b = Plots.plot(1:n:T, estimated_θ2_mean[1:n:T], ribbon=[estimated_θ2_std[1:n:T], estimated_θ2_std[1:n:T]], color=\"blue\", label=\"θ_2\", xlabel=\"time (t)\")\n",
    "    p2c = Plots.plot(1:n:T, estimated_θ3_mean[1:n:T], ribbon=[estimated_θ3_std[1:n:T], estimated_θ3_std[1:n:T]], color=\"green\", label=\"θ_3\", xlabel=\"time (t)\")\n",
    "    p2 = plot(p2a, p2b, p2c, layout=(3,1), size=(800,1200))\n",
    "#     Plots.savefig(p2, \"viz/nonlin_estimated_θ.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of control coefficient marginals\n",
    "estimated_η_mean = params_η[1][1,2:end]\n",
    "estimated_η_std = sqrt.(inv.(params_η[2][1,2:end]))\n",
    "\n",
    "if viz\n",
    "    # Plot both coefficients next to each other\n",
    "    p3 = Plots.plot(1:n:T, estimated_η_mean[1:n:T], ribbon=[estimated_η_std[1:n:T], estimated_η_std[1:n:T]], color=\"blue\", label=\"η\", xlabel=\"time (t)\", ylim=[-.5, 1.], size=(800,400))\n",
    "#     Plots.savefig(p3, \"viz/nonlin_estimated_η.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of process precision marginals\n",
    "estimated_γ_mean = params_γ[1][1,2:end] ./ params_γ[2][1,2:end]\n",
    "estimated_γ_std = sqrt.(params_γ[1][1,2:end] ./ params_γ[2][1,2:end].^2)\n",
    "\n",
    "if viz\n",
    "    # Plot both coefficients next to each other\n",
    "    p4 = Plots.plot(1:n:T, estimated_γ_mean[1:n:T], ribbon=[estimated_γ_std[1:n:T], estimated_γ_std[1:n:T]], color=\"blue\", label=\"γ\", xlabel=\"time (t)\", size=(800,400))\n",
    "#     Plots.savefig(p4, \"viz/nonlin_estimated_γ.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of measurement precision marginals\n",
    "estimated_ξ_mean = params_ξ[1][1,2:end] ./ params_ξ[2][1,2:end]\n",
    "estimated_ξ_std = sqrt.(params_ξ[1][1,2:end] ./ params_ξ[2][1,2:end].^2)\n",
    "\n",
    "if viz\n",
    "    # Plot both coefficients next to each other\n",
    "    p8 = Plots.plot(1:n:T, estimated_ξ_mean[1:n:T], ribbon=[estimated_ξ_std[1:n:T], estimated_ξ_std[1:n:T]], color=\"blue\", label=\"measurement-precision\", xlabel=\"time (t)\", size=(600,400), legend=:bottomright)\n",
    "#     Plots.savefig(p8, \"viz/nonlin_estimated_measurement-precision_600x400.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize estimates of mass\n",
    "p11 = plot(1:n:T, params_m[1][1:n:T], ribbon=[sqrt.(params_m[2][1:n:T]) sqrt.(params_m[2][1:n:T])], label=\"mass\", legend=:bottomright)\n",
    "# Plots.savefig(p11, \"viz/nonlin-1taylor_estimated_mass.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize estimates of friction\n",
    "p12 = plot(1:n:T, params_v[1][1:n:T], ribbon=[sqrt.(params_v[2][1:n:T]) sqrt.(params_v[2][1:n:T])], label=\"friction\", legend=:bottomright)\n",
    "# Plots.savefig(p12, \"viz/nonlin-1taylor_estimated_friction.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize estimates of linear stiffness\n",
    "p13 = plot(1:n:T, params_a[1][1:n:T], ribbon=[sqrt.(params_a[2][1:n:T]) sqrt.(params_a[2][1:n:T])], label=\"linear-stiffness\", legend=:bottomright)\n",
    "# Plots.savefig(p13, \"viz/nonlin-1taylor_estimated_lin-stiffness.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize estimates of nonlinear stiffness\n",
    "p14 = plot(1:n:T, params_b[1][1:n:T], ribbon=[sqrt.(params_b[2][1:n:T]) sqrt.(params_b[2][1:n:T])], label=\"nonlin-stiffness\", legend=:bottomright)\n",
    "# Plots.savefig(p14, \"viz/nonlin-1taylor_estimated_nonlin-stiffness.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map process noise back to log-normal distribution\n",
    "m_lτ = exp.(params_τ[1] .+ params_τ[2]./ 2.)\n",
    "v_lτ = exp.(2 .*params_τ[1] .+ params_τ[2]).*(exp.(params_τ[2]) .- 1)\n",
    "\n",
    "# Visualize estimates of process noise\n",
    "# plot(1:n:T, params_τ[1][1:n:T], ribbon=[sqrt.(params_τ[2][1:n:T]) sqrt.(params_τ[2][1:n:T])], label=\"process-noise\", legend=:bottomright)\n",
    "p15 = plot(1:n:T, m_lτ[1:n:T], ribbon=[sqrt.(v_lτ[1:n:T]) sqrt.(v_lτ[1:n:T])], label=\"process-noise\", legend=:bottomright)\n",
    "# Plots.savefig(p15, \"viz/nonlin-1taylor_estimated_process-noise.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
