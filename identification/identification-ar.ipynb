{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silverbox\n",
    "\n",
    "Silverbox refers to one of the nonlinear system identification benchmarks on http://nonlinearbenchmark.org/#Silverbox. \n",
    "It is a set of measurements of an electronic implementation of a [Duffing oscillator](https://en.wikipedia.org/wiki/Duffing_equation).\n",
    "\n",
    "State-space model of the system:\n",
    "\n",
    "$$\\begin{align}\n",
    "m \\frac{d^2 x(t)}{dt^2} + v \\frac{d x(t)}{dt} + a x(t) + b x^3(t) =&\\ u(t) + w(t) \\\\\n",
    "y(t) =&\\ x(t) + e(t)\n",
    "\\end{align}$$\n",
    "\n",
    "where\n",
    "$$\\begin{align}\n",
    "m     =&\\ \\text{mass} \\\\\n",
    "v     =&\\ \\text{viscous damping} \\\\\n",
    "a     =&\\ \\text{linear stiffness} \\\\\n",
    "b     =&\\ \\text{nonlinear stiffness} \\\\\n",
    "y(t)    =&\\ \\text{observation (displacement)} \\\\\n",
    "x(t)    =&\\ \\text{state (displacement)} \\\\\n",
    "u(t)    =&\\ \\text{force} \\\\\n",
    "e(t)    =&\\ \\text{measurement noise} \\\\\n",
    "w(t)    =&\\ \\text{process noise}\n",
    "\\end{align}$$\n",
    "\n",
    "The process noise is a Wiener process, where the increment is Gaussian distributed:\n",
    "\n",
    "$$\\begin{align}\n",
    "w(t) =&\\ \\frac{d B(t)}{dt} \\sim \\mathcal{N}(0, \\tau^{-1}dt)\n",
    "\\end{align}$$\n",
    "\n",
    "The parameter $\\tau$ represents the precision of the process. The same holds for the measurement noise.\n",
    "\n",
    "## Solution steps\n",
    "\n",
    "### 1. Ignore nonlinear stiffness\n",
    "\n",
    "For now, we ignore the nonlinear stiffness component by setting the parameter $b$ to 0. The state transition thus reduces to:\n",
    "\n",
    "$$\\begin{align}\n",
    "m x''(t) + v x'(t) + a x(t) = u(t) + w(t) \n",
    "\\end{align}$$\n",
    "\n",
    "### 2. Discretize using finite-differences\n",
    "\n",
    "I'm using an implicit method, for stability reasons.\n",
    "The backward difference for both derivative terms:\n",
    "\n",
    "$$\\begin{align}\n",
    "x''(t) \\approx&\\ \\frac{x(t) - 2x(t-h) + x(t-2h)}{h^2} = \\frac{x_t - 2x_{t-1} + x_{t-2}}{(\\Delta t)^2}\\\\\n",
    "x'(t) \\approx&\\ \\frac{x(t) - x(t-h)}{h} = \\frac{x_t - x_{t-1}}{\\Delta t}\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "where $\\Delta t = t - (t-1) = 1$. A discretization of the Wiener process yields:\n",
    "\n",
    "$$\\begin{align}\n",
    "w(t) = \\frac{dB(t)}{dt} \\approx \\frac{B(t) - B(t-h)}{h} = \\frac{B_t - B_{t-1}}{\\Delta t} \\sim \\mathcal{N}(0, \\tau^{-1}\\Delta t) \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "Let $w_t$ be a sample from $\\mathcal{N}(0, \\tau^{-1})$. The control signal $u(t)$ was constructed from a discrete signal, converted into an analogue signal through a zero-order-hold filter. That means it's a step-function: constant between any $t$ and $t-1$. Since it is an observed variable, we can just convert $u(t)$ straight to $u_t$. The DE can now be written as the following discrete-time system:\n",
    "\n",
    "$$m (x_t - 2x_{t-1} + x_{t-2}) + v (x_t - x_{t-1}) + a x_t = u_t + w_t$$\n",
    "\n",
    "Re-writing this in terms of $x_t$ yields:\n",
    "$$\\begin{align}\n",
    "(m + v + a) x_t&\\ + (-2m - v) x_{t-1} + m x_{t-2} = u_t + w_t \\\\\n",
    "% x_t + \\frac{-2m - v}{m + v + a} x_{t-1} + \\frac{m}{m + v + a} x_{t-2} =&\\ \\frac{1}{m + v + a} u_t + \\frac{1}{m + v + a} w_t \\\\\n",
    "x_t&\\ = \\frac{2m + v}{m + v + a} x_{t-1} + \\frac{-m}{m + v + a} x_{t-2} + \\frac{1}{m + v + a} u_t + \\frac{1}{m + v + a} w_t \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "### 3. Substitute variables:\n",
    "\n",
    "I'm substituting variables to clean the equation up a bit:\n",
    "\n",
    "$$\\begin{align} \n",
    "\\theta_1 =&\\ \\frac{2m + v}{m + v + a} \\\\\n",
    "\\theta_2 =&\\ \\frac{-m}{m + v + a} \\\\\n",
    "\\eta =&\\ \\frac{1}{m + v + a} \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "This produces:\n",
    "$$\\begin{align}\n",
    "x_t = \\theta_1 x_{t-1} + \\theta_2 x_{t-2} + \\eta u_t + \\eta w_t\n",
    "\\end{align}$$\n",
    "\n",
    "I'm going to absorb $\\eta$ into $w_t$ (using $\\mathbb{V}[aX] = a^2\\mathbb{V}[X]$):\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{V}[\\eta w_t] = \\eta^2 \\mathbb{V}[w_t] = \\eta^2 \\tau^{-1}\n",
    "\\end{align}$$\n",
    "\n",
    "I will rename $\\eta^2 \\tau^{-1}$ as $\\gamma^{-1}$. This yields\n",
    "\n",
    "$$\\begin{align}\n",
    "x_t = \\theta_1 x_{t-1} + \\theta_2 x_{t-2} + \\eta u_t + \\tilde{w}_t\n",
    "\\end{align}$$\n",
    "\n",
    "where $\\tilde{w}_t \\sim \\mathcal{N}(0, \\gamma^{-1})$. Given four equations and four unknowns, I can recover $m$, $v$, $a$ and $\\tau$ from $\\theta_1$, $\\theta_2$, $\\eta$ and $\\gamma$.\n",
    "\n",
    "### 4. Cast to multivariate first-order form\n",
    "\n",
    "The system now resembles an auto-regressive process:\n",
    "\n",
    "$$ \\underbrace{\\begin{bmatrix} x_t \\\\ x_{t-1} \\end{bmatrix}}_{z_t} = \\underbrace{\\begin{bmatrix} \\theta_1 & \\theta_2 \\\\ 1 & 0 \\end{bmatrix}}_{A(\\theta)} \\underbrace{\\begin{bmatrix} x_{t-1} \\\\ x_{t-2} \\end{bmatrix}}_{z_{t-1}} + \\underbrace{\\begin{bmatrix} \\eta \\\\ 0 \\end{bmatrix}}_{B(\\eta)} u_t + \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\tilde{w}_t \\, .$$\n",
    "\n",
    "Note that we need a two-dimensional state prior now (reminiscent of adding an initial condition on the velocity).\n",
    "\n",
    "### 5. Convert to Gaussian probability\n",
    "\n",
    "The state transition maps to\n",
    "\n",
    "$$z_t \\sim \\mathcal{N}(A(\\theta) z_{t-1} + c\\eta u_t, V)$$\n",
    "\n",
    "where $V = \\begin{bmatrix} \\gamma^{-1} & 0 \\\\ 0 & \\epsilon \\end{bmatrix}$ and $V^{-1} = W = \\begin{bmatrix} \\gamma & 0 \\\\ 0 & \\epsilon^{-1} \\end{bmatrix}$.\n",
    "\n",
    "The observation likelihood maps to\n",
    "\n",
    "$$y_t \\sim \\mathcal{N}(c^{\\top} z_t, \\xi^{-1})$$\n",
    "\n",
    "where $c = \\begin{bmatrix} 1 & 0 \\end{bmatrix}$ and $e_t \\sim \\mathcal{N}(0, \\xi^{-1})$.\n",
    "\n",
    "### 6. Choose priors\n",
    "\n",
    "We currently have unknown parameters $\\psi = (\\theta_1, \\theta_2, \\eta, \\gamma)$. Since they are substitutions, we don't know anything about their support directly. We do know about it indirectly, from the nonlinear combinations of the physical coefficients. We know that mass $m$ and process precision $\\gamma$ are strictly positive parameters and that the damping and stiffness coefficients can be both positive and negative. Hence, by examing the nonlinear transform $\\psi = G(\\phi)$;\n",
    "\n",
    "$$\\begin{align} \n",
    "\\theta_1 =&\\ \\frac{2m + v}{m + v + a} \\\\\n",
    "\\theta_2 =&\\ \\frac{-m}{m + v + a} \\\\\n",
    "\\eta =&\\ \\frac{1}{m + v + a} \\\\\n",
    "\\gamma^{-1} =&\\ \\frac{1}{\\tau(m + v+ a)^2} \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "we realize that $\\theta_1$, $\\theta_2$ and $\\eta$ can be both positive and negative, but $\\gamma$ can only be positive. As such, we choose the following priors:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\theta \\sim&\\ \\mathcal{N}(m^{0}_{\\theta}, V^{0}_{\\theta}) \\\\\n",
    "\\eta \\sim&\\ \\mathcal{N}(m^{0}_{\\eta}, v^{0}_{\\eta}) \\\\ \n",
    "\\gamma \\sim&\\ \\Gamma(a^{0}_\\gamma, b^{0}_\\gamma) \n",
    "\\end{align}$$\n",
    "\n",
    "Modeling $\\theta = (\\theta_1, \\theta_2)$ as a joint Gaussian allows for incorporating it into an Autoregressive node.\n",
    "\n",
    "### 7. Recover physical variables from substituted ones\n",
    "\n",
    "Since we have four equations and four unknowns, we can perfectly recover point estimates of the physical variables from substituted ones. However, we don't want point estimates, we want posteriors. \n",
    "\n",
    "If we approximate $\\gamma$ with a log-Normal distribution and then map it to a Gaussian distribution (i.e. model $\\log(\\gamma)$), we end up with a Gaussian distributed random vector $\\psi = [\\theta_1, \\theta_2, \\eta, \\log(\\gamma)]$. We can perform a Gaussian approximation of the inverse mapping $G^{-1}(\\psi)$ using a first-order Taylor expansion:\n",
    "\n",
    "$$\\begin{align}\n",
    "m_{\\phi} \\triangleq \\mathbb{E}[G^{-1}(\\psi)] =&\\ G^{-1}(m_{\\psi} \\\\\n",
    "V_{\\phi} \\triangleq \\mathbb{V}[G^{-1}(\\psi)] =&\\ J_{\\psi}(m_{\\psi}) G^{-1}(m_{\\psi} J_{\\psi}(m_{\\psi})^{\\top} \\, ,\n",
    "\\end{align}$$\n",
    "\n",
    "Since each component of $\\phi$ is Gaussian distributed, we have actually modeled $\\log(m)$ and $\\log(\\tau)$. We still need to map these to log-Normal distributions to recover $m$ and $\\tau$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Let's first have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using CSV\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "viz = false;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV file\n",
    "df = CSV.read(\"../data/SNLS80mV.csv\", ignoreemptylines=true)\n",
    "df = select(df, [:V1, :V2])\n",
    "\n",
    "# Shorthand\n",
    "input = df[:,1]\n",
    "output = df[:,2]\n",
    "\n",
    "# Time horizon\n",
    "T = size(df, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot every n-th time-point to avoid figure size exploding\n",
    "n = 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot output signal (observed displacement)\n",
    "if viz  \n",
    "    p1 = Plots.scatter(1:n:T, output[1:n:T], color=\"black\", label=\"output\", markersize=2, size=(1600,800), xlabel=\"time (t)\", ylabel=\"response\")\n",
    "    # Plots.savefig(p1, \"viz/output_signal.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot input signal (control)\n",
    "if viz\n",
    "    p2 = Plots.scatter(1:n:T, input[1:n:T], color=\"blue\", label=\"output\", markersize=2, size=(1600,800), xlabel=\"time (t)\", ylabel=\"control\")\n",
    "    # Plots.savefig(p2, \"viz/input_signal.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating parameters via Bayesian filtering\n",
    "\n",
    "Implementation with ForneyLab and AR node. The AR node comes from the package LAR (https://github.com/biaslab/LAR/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using ForneyLab\n",
    "import ForneyLab: unsafeMean, unsafeCov, unsafeVar, unsafePrecision\n",
    "using ProgressMeter\n",
    "\n",
    "include(\"../ARC-node/ARC.jl\")\n",
    "using .ARC.Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote\n",
    "\n",
    "function Jacobian(F, x)\n",
    "    y = F(x)\n",
    "    n = length(y)\n",
    "    m = length(x)\n",
    "    T = eltype(y)\n",
    "    j = Array{T, 2}(undef, n, m)\n",
    "    for i in 1:n\n",
    "        j[i, :] .= gradient(x -> F(x)[i], x)[1]\n",
    "    end\n",
    "    return j\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start graph\n",
    "graph = FactorGraph()\n",
    "\n",
    "# Coefficients\n",
    "@RV θ ~ GaussianMeanPrecision(placeholder(:m_θ, dims=(2,)), placeholder(:w_θ, dims=(2,2)))\n",
    "@RV η ~ GaussianMeanPrecision(placeholder(:m_η), placeholder(:w_η))\n",
    "@RV γ ~ Gamma(placeholder(:a_γ), placeholder(:b_γ))\n",
    "@RV ξ ~ Gamma(placeholder(:a_ξ), placeholder(:b_ξ))\n",
    "@RV u_t\n",
    "\n",
    "# State prior\n",
    "@RV x_t_prev ~ GaussianMeanPrecision(placeholder(:m_x_t_prev, dims=(2,)), placeholder(:w_x_t_prev, dims=(2, 2)))\n",
    "\n",
    "# Autoregressive node\n",
    "@RV x_t ~ Autoregressive(θ, x_t_prev, γ)\n",
    "\n",
    "# Control term\n",
    "@RV Bu = [1., 0.]*(u_t*η)\n",
    "\n",
    "# Add control\n",
    "@RV z_t = x_t + Bu\n",
    "\n",
    "# Select first element\n",
    "@RV z_1 = dot([1., 0.], z_t)\n",
    "\n",
    "# Specify likelihood\n",
    "@RV y_t ~ GaussianMeanPrecision(z_1, ξ)\n",
    "\n",
    "# Placeholders\n",
    "placeholder(y_t, :y_t)\n",
    "placeholder(u_t, :u_t)\n",
    "\n",
    "# Draw time-slice subgraph\n",
    "ForneyLab.draw(graph)\n",
    "\n",
    "# Inference algorithm\n",
    "q = PosteriorFactorization([x_t, x_t_prev], θ, γ, ξ, ids=[:x, :θ, :γ, :ξ])\n",
    "# q = PosteriorFactorization([z_t, x_t_prev], θ, η, γ, ξ, ids=[:x, :θ, :η, :γ, :ξ])\n",
    "algo = variationalAlgorithm(q, free_energy=true)\n",
    "source_code = algorithmSourceCode(algo, free_energy=true)\n",
    "eval(Meta.parse(source_code))\n",
    "println(source_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin\n",
    "\n",
    "function stepγ!(data::Dict, marginals::Dict=Dict(), messages::Vector{Message}=Array{Message}(undef, 2))\n",
    "\n",
    "messages[1] = ruleVBGammaOut(nothing, ProbabilityDistribution(Univariate, PointMass, m=data[:a_γ]), ProbabilityDistribution(Univariate, PointMass, m=data[:b_γ]))\n",
    "messages[2] = ruleSVariationalARIn3PPPN(marginals[:x_t_x_t_prev], marginals[:θ], nothing)\n",
    "\n",
    "marginals[:γ] = messages[1].dist * messages[2].dist\n",
    "\n",
    "return marginals\n",
    "\n",
    "end\n",
    "\n",
    "function stepξ!(data::Dict, marginals::Dict=Dict(), messages::Vector{Message}=Array{Message}(undef, 2))\n",
    "\n",
    "messages[1] = ruleVBGammaOut(nothing, ProbabilityDistribution(Univariate, PointMass, m=data[:a_ξ]), ProbabilityDistribution(Univariate, PointMass, m=data[:b_ξ]))\n",
    "messages[2] = ruleVBGaussianMeanPrecisionW(ProbabilityDistribution(Univariate, PointMass, m=data[:y_t]), marginals[:z_1], nothing)\n",
    "\n",
    "marginals[:ξ] = messages[1].dist * messages[2].dist\n",
    "\n",
    "return marginals\n",
    "\n",
    "end\n",
    "\n",
    "function stepθ!(data::Dict, marginals::Dict=Dict(), messages::Vector{Message}=Array{Message}(undef, 2))\n",
    "\n",
    "messages[1] = ruleVBGaussianMeanPrecisionOut(nothing, ProbabilityDistribution(Multivariate, PointMass, m=data[:m_θ]), ProbabilityDistribution(MatrixVariate, PointMass, m=data[:w_θ]))\n",
    "messages[2] = ruleSVariationalARIn2PPNP(marginals[:x_t_x_t_prev], nothing, marginals[:γ])\n",
    "\n",
    "marginals[:θ] = messages[1].dist * messages[2].dist\n",
    "\n",
    "return marginals\n",
    "\n",
    "end\n",
    "\n",
    "function stepx!(data::Dict, marginals::Dict=Dict(), messages::Vector{Message}=Array{Message}(undef, 14))\n",
    "\n",
    "messages[1] = ruleVBGaussianMeanPrecisionOut(nothing, ProbabilityDistribution(Univariate, PointMass, m=data[:m_η]), ProbabilityDistribution(Univariate, PointMass, m=data[:w_η]))\n",
    "messages[2] = ruleVBGaussianMeanPrecisionM(ProbabilityDistribution(Univariate, PointMass, m=data[:y_t]), nothing, marginals[:ξ])\n",
    "messages[3] = ruleSPDotProductIn1GNP(messages[2], nothing, Message(Multivariate, PointMass, m=[1.0, 0.0]))\n",
    "messages[4] = ruleVBGaussianMeanPrecisionOut(nothing, ProbabilityDistribution(Multivariate, PointMass, m=data[:m_x_t_prev]), ProbabilityDistribution(MatrixVariate, PointMass, m=data[:w_x_t_prev]))\n",
    "messages[5] = ruleSVariationalAROutNPPP(nothing, messages[4], marginals[:θ], marginals[:γ])\n",
    "messages[6] = ruleSPAdditionIn2GGN(messages[3], messages[5], nothing)\n",
    "messages[7] = ruleSPMultiplicationIn1GNP(messages[6], nothing, Message(Multivariate, PointMass, m=[1.0, 0.0]))\n",
    "messages[8] = ruleSPMultiplicationIn1GNP(messages[7], nothing, Message(Univariate, PointMass, m=data[:u_t]))\n",
    "messages[9] = ruleSPMultiplicationOutNGP(nothing, messages[1], Message(Univariate, PointMass, m=data[:u_t]))\n",
    "messages[10] = ruleSPMultiplicationOutNGP(nothing, messages[9], Message(Multivariate, PointMass, m=[1.0, 0.0]))\n",
    "messages[11] = ruleSPAdditionOutNGG(nothing, messages[5], messages[10])\n",
    "messages[12] = ruleSPDotProductOutNGP(nothing, messages[11], Message(Multivariate, PointMass, m=[1.0, 0.0]))\n",
    "messages[13] = ruleSPAdditionIn1GNG(messages[3], nothing, messages[10])\n",
    "messages[14] = ruleSVariationalARIn1PNPP(messages[13], nothing, marginals[:θ], marginals[:γ])\n",
    "\n",
    "marginals[:variable_2] = messages[10].dist * messages[6].dist\n",
    "marginals[:x_t] = messages[5].dist * messages[13].dist\n",
    "marginals[:x_t_prev] = messages[4].dist * messages[14].dist\n",
    "marginals[:z_1] = messages[12].dist * messages[2].dist\n",
    "marginals[:η] = messages[1].dist * messages[8].dist\n",
    "marginals[:x_t_variable_2] = ruleMAdditionNGG(messages[3], messages[5], messages[10])\n",
    "marginals[:x_t_x_t_prev] = ruleMGaussianMeanVarianceGGGD(messages[13], messages[4], marginals[:θ], marginals[:γ])\n",
    "\n",
    "return marginals\n",
    "\n",
    "end\n",
    "\n",
    "function freeEnergy(data::Dict, marginals::Dict)\n",
    "\n",
    "F = 0.0\n",
    "\n",
    "F += averageEnergy(Autoregressive, marginals[:x_t_x_t_prev], marginals[:θ], marginals[:γ])\n",
    "F += averageEnergy(Gamma, marginals[:γ], ProbabilityDistribution(Univariate, PointMass, m=data[:a_γ]), ProbabilityDistribution(Univariate, PointMass, m=data[:b_γ]))\n",
    "F += averageEnergy(Gamma, marginals[:ξ], ProbabilityDistribution(Univariate, PointMass, m=data[:a_ξ]), ProbabilityDistribution(Univariate, PointMass, m=data[:b_ξ]))\n",
    "F += averageEnergy(GaussianMeanPrecision, marginals[:θ], ProbabilityDistribution(Multivariate, PointMass, m=data[:m_θ]), ProbabilityDistribution(MatrixVariate, PointMass, m=data[:w_θ]))\n",
    "F += averageEnergy(GaussianMeanPrecision, marginals[:η], ProbabilityDistribution(Univariate, PointMass, m=data[:m_η]), ProbabilityDistribution(Univariate, PointMass, m=data[:w_η]))\n",
    "F += averageEnergy(GaussianMeanPrecision, marginals[:x_t_prev], ProbabilityDistribution(Multivariate, PointMass, m=data[:m_x_t_prev]), ProbabilityDistribution(MatrixVariate, PointMass, m=data[:w_x_t_prev]))\n",
    "F += averageEnergy(GaussianMeanPrecision, ProbabilityDistribution(Univariate, PointMass, m=data[:y_t]), marginals[:z_1], marginals[:ξ])\n",
    "\n",
    "F -= -1*differentialEntropy(marginals[:variable_2])\n",
    "F -= -1*differentialEntropy(marginals[:x_t])\n",
    "F -= differentialEntropy(marginals[:x_t_variable_2])\n",
    "F -= differentialEntropy(marginals[:x_t_x_t_prev])\n",
    "F -= differentialEntropy(marginals[:γ])\n",
    "F -= differentialEntropy(marginals[:η])\n",
    "F -= differentialEntropy(marginals[:θ])\n",
    "F -= differentialEntropy(marginals[:ξ])\n",
    "\n",
    "return F\n",
    "\n",
    "end\n",
    "\n",
    "end # block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at only the first few timepoints\n",
    "# T = 100\n",
    "T = size(df, 1);\n",
    "\n",
    "# Inference parameters\n",
    "num_iterations = 10\n",
    "\n",
    "# Initialize marginal distribution and observed data dictionaries\n",
    "data = Dict()\n",
    "marginals = Dict()\n",
    "\n",
    "# Initialize arrays of parameterizations\n",
    "params_x = (zeros(2,T+1), repeat(.1 .*float(eye(2)), outer=(1,1,T+1)))\n",
    "params_θ = (ones(2,T+1), repeat(.1 .*float(eye(2)), outer=(1,1,T+1)))\n",
    "params_η = (ones(1,T+1), .1*ones(1,T+1))\n",
    "params_γ = (ones(1,T+1), ones(1,T+1))\n",
    "params_ξ = (1e4*ones(1,T+1), 1e1*ones(1,T+1))\n",
    "\n",
    "# Initialize physical coefficient estimate arrays\n",
    "params_m = (zeros(T,), zeros(T,))\n",
    "params_v = (zeros(T,), zeros(T,))\n",
    "params_a = (zeros(T,), zeros(T,))\n",
    "params_τ = (zeros(T,), zeros(T,))\n",
    "\n",
    "# Initialize message array\n",
    "messages = Array{Message}(undef, 14)\n",
    "\n",
    "# Initialize free energy array\n",
    "FE = zeros(T,num_iterations)\n",
    "\n",
    "# Start progress bar\n",
    "p = Progress(T, 1, \"At time \")\n",
    "\n",
    "# Perform inference at each time-step\n",
    "for t = 1:T\n",
    "\n",
    "    # Update progress bar\n",
    "    update!(p, t)\n",
    "    \n",
    "    \"Filtering\"\n",
    "\n",
    "    # Initialize marginals\n",
    "    marginals[:x_t_x_t_prev] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=zeros(4,), w=float(eye(4)))\n",
    "    marginals[:x_t_prev] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_x[1][:,t], w=params_x[2][:,:,t])\n",
    "    marginals[:x_t_Bu] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=zeros(2,), w=float(eye(2)))\n",
    "    marginals[:x_t] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_x[1][:,t], w=params_x[2][:,:,t])\n",
    "    marginals[:z_t] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_x[1][:,t], w=params_x[2][:,:,t])\n",
    "    marginals[:z_1] = ProbabilityDistribution(Univariate, GaussianMeanPrecision, m=params_x[1][1,t], w=params_x[2][1,1,t])\n",
    "    marginals[:Bu] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=zeros(2,), w=float(eye(2)))\n",
    "    marginals[:θ] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=params_θ[1][:,t], w=params_θ[2][:,:,t])\n",
    "    marginals[:η] = ProbabilityDistribution(Univariate, GaussianMeanPrecision, m=params_η[1][1,t], w=params_η[2][1,t])\n",
    "    marginals[:γ] = ProbabilityDistribution(Univariate, Gamma, a=params_γ[1][1,t], b=params_γ[2][1,t])\n",
    "    marginals[:ξ] = ProbabilityDistribution(Univariate, Gamma, a=params_ξ[1][1,t], b=params_ξ[2][1,t])\n",
    "    \n",
    "    # Set clamped variables\n",
    "    data = Dict(:y_t => output[t],\n",
    "                :u_t => input[t],\n",
    "                :m_x_t_prev => params_x[1][:,t],\n",
    "                :w_x_t_prev => params_x[2][:,:,t],\n",
    "                :m_θ => params_θ[1][:,t],\n",
    "                :w_θ => params_θ[2][:,:,t],\n",
    "                :m_η => params_η[1][1,t],\n",
    "                :w_η => params_η[2][1,t],\n",
    "                :a_γ => params_γ[1][1,t],\n",
    "                :b_γ => params_γ[2][1,t],\n",
    "                :a_ξ => params_ξ[1][1,t],\n",
    "                :b_ξ => params_ξ[2][1,t])\n",
    "    \n",
    "    # Iterate variational parameter updates\n",
    "    for i = 1:num_iterations\n",
    "        \n",
    "        # Compute Free Energy\n",
    "        FE[t,i] = freeEnergy(data, marginals)\n",
    "\n",
    "        # Update recognition factors\n",
    "        stepx!(data, marginals, messages)\n",
    "        stepθ!(data, marginals)\n",
    "#         stepη!(data, marginals)\n",
    "        stepγ!(data, marginals)\n",
    "        stepξ!(data, marginals)\n",
    "        \n",
    "        # Update marginal of z_t manually\n",
    "        marginals[:z_t] = messages[13].dist*messages[3].dist\n",
    "    end\n",
    "    \n",
    "    # Store current parameterizations of marginals\n",
    "    params_x[1][:,t+1] = mean(marginals[:z_t])\n",
    "    params_x[2][:,:,t+1] = marginals[:z_t].params[:w]\n",
    "    params_θ[1][:,t+1] = mean(marginals[:θ])\n",
    "    params_θ[2][:,:,t+1] = marginals[:θ].params[:w]\n",
    "    params_η[1][1,t+1] = mean(marginals[:η])\n",
    "    params_η[2][1,t+1] = marginals[:η].params[:w]\n",
    "    params_γ[1][1,t+1] = marginals[:γ].params[:a]\n",
    "    params_γ[2][1,t+1] = marginals[:γ].params[:b]\n",
    "    params_ξ[1][1,t+1] = marginals[:ξ].params[:a]\n",
    "    params_ξ[2][1,t+1] = marginals[:ξ].params[:b]\n",
    "    \n",
    "    \"Map substituted to physical variables via first-order Taylor\"\n",
    "    \n",
    "    # Approximate gamma with log-normal via moment-matching\n",
    "    Eγ = unsafeMean(marginals[:γ])\n",
    "    Vγ = unsafeVar(marginals[:γ])\n",
    "    m_γ = log(Eγ^2/sqrt(Vγ + Eγ^2))\n",
    "    v_γ = log(Vγ/Eγ^2 + 1)\n",
    "\n",
    "    # Construct vector of parameter estimates ψ\n",
    "    m_ψ = [unsafeMean(marginals[:θ])[1], unsafeMean(marginals[:θ])[2], unsafeMean(marginals[:η])[1], m_γ]\n",
    "    V_ψ = [unsafeCov(marginals[:θ]) zeros(2,2); zeros(2,2) [unsafeCov(marginals[:η])[1,1] 0;0 v_γ]]\n",
    "\n",
    "    # Transformation: ψ = G(ϕ) => ϕ = G_inv(ψ)\n",
    "    G_inv(ψ) = [-ψ[2]/ψ[3], (ψ[1] + 2*ψ[2])/ψ[3], (-ψ[1] -ψ[2] +1)/ψ[3], ψ[4]/ψ[3]^2]\n",
    "    \n",
    "    # Compute Jacobian of transformation \n",
    "    J_mϕ = Jacobian(G_inv, m_ψ)\n",
    "    \n",
    "    # Compute moments of transformed Gaussian using first-order Taylor approx\n",
    "    m_ϕ = G_inv(m_ψ)\n",
    "    V_ϕ = J_mϕ*V_ψ*J_mϕ'\n",
    "\n",
    "    # Split ϕ into physical coefficients\n",
    "    m_m, m_v, m_a, m_τ = m_ϕ\n",
    "    v_m, v_v, v_a, v_τ = Diagonal(V_ϕ)\n",
    "    \n",
    "    # Store param estimates for mass\n",
    "    params_m[1][t] = m_m\n",
    "    params_m[2][t] = v_m\n",
    "    \n",
    "    # Store param estimates for friction\n",
    "    params_v[1][t] = m_v\n",
    "    params_v[2][t] = v_v\n",
    "    \n",
    "    # Store param estimates for linear stiffness\n",
    "    params_a[1][t] = m_a\n",
    "    params_a[2][t] = v_a\n",
    "    \n",
    "    # Store param estimates for process precision\n",
    "    params_τ[1][t] = m_τ\n",
    "    params_τ[2][t] = v_τ\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize FE\n",
    "p00 = plot(mean(FE[1:100,1:end], dims=1)', color=\"black\", ylabel=\"FE\", xlabel=\"#iterations\", label=\"\", legend=:topleft, title=\"Average FE for first 100 samples\", ylims=[13.901, 13.914])\n",
    "# Plots.savefig(p00, \"viz/FE_t_first100.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize FE\n",
    "p02 = plot(mean(FE[1001:end,:], dims=1)', color=\"black\", ylabel=\"FE\", xlabel=\"#iterations\", label=\"\", legend=:topleft, title=\"Average FE after burn-in (>1000)\", ylims=[10.25, 10.4])\n",
    "# Plots.savefig(p02, \"viz/FE_t_1000onwards.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize FE over time\n",
    "p01 = plot(FE[:,end], color=\"black\", ylabel=\"FE_t\", xlabel=\"time (t)\", label=\"\", title=\"Final FE at each time step\", ylims=[10., 13.])\n",
    "# Plots.savefig(p01, \"viz/FE_t.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot every n-th time-point to avoid large figure filesizes\n",
    "n = 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot estimated states\n",
    "p1 = Plots.scatter(1:n:T, output[1:n:T], color=\"black\", label=\"output\", markersize=2, size=(1400,600), xlabel=\"time (t)\", ylabel=\"response\")\n",
    "Plots.plot!(1:n:T, params_x[1][1,2:n:end], color=\"red\", linewidth=1, label=\"estimated\")\n",
    "# Plots.savefig(p1, \"viz/estimated_states01.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize estimates of mass\n",
    "plot(1:n:T, params_m[1][2:n:T], ribbon=[sqrt.(params_m[2][2:n:T]) sqrt.(params_m[2][2:n:T])], label=\"mass\", legend=:bottomright, ylim=[-5.,10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize estimates of friction\n",
    "plot(1:n:T, params_v[1][1:n:T], ribbon=[sqrt.(params_v[2][1:n:T]) sqrt.(params_v[2][1:n:T])], label=\"friction\", legend=:bottomright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize estimates of linear stiffness\n",
    "plot(1:n:T, params_a[1][1:n:T], ribbon=[sqrt.(params_a[2][1:n:T]) sqrt.(params_a[2][1:n:T])], label=\"stiffness-a\", legend=:bottomright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize estimates of process noise\n",
    "plot(1:n:T, params_τ[1][1:n:T], ribbon=[sqrt.(params_τ[2][1:n:T]) sqrt.(params_τ[2][1:n:T])], label=\"process-noise\", legend=:bottomright, yscale=:log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize estimates of measurement noise\n",
    "mean_ξ_inv = params_ξ[1] ./ params_ξ[2]\n",
    "var_ξ_inv = params_ξ[1] ./ params_ξ[2].^2\n",
    "plot(1:n:T, mean_ξ_inv[1:n:T], ribbon=[sqrt.(var_ξ_inv[1:n:T]) sqrt.(var_ξ_inv[1:n:T])], label=\"measurement-noise\", legend=:bottomright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
